<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>aws on CodeWithStu's Blog</title><link>https://im5tu.io/tags/aws/</link><description>Recent content in aws on CodeWithStu's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Mon, 24 Apr 2023 01:00:00 +0000</lastBuildDate><atom:link href="https://im5tu.io/tags/aws/index.xml" rel="self" type="application/rss+xml"/><item><title>Observed No. 11 - Saving Costs on AWS</title><link>https://im5tu.io/article/2023/04/observed-no.-11-saving-costs-on-aws/</link><pubDate>Mon, 24 Apr 2023 01:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/04/observed-no.-11-saving-costs-on-aws/</guid><description>&lt;p>Welcome to the 11th edition of Observed! The newsletter delivers a tip you can implement across many categories like AWS, Terraform and General DevOps practices in your infrastructure. This week&amp;rsquo;s edition looks at AWS Cost Savings.&lt;/p>
&lt;p>Every company seems to be cutting costs in one way or another. Letâ€™s look at different ways you can visualize and reduce costs.&lt;/p>
&lt;h2 id="aws-cost-explorer">AWS Cost Explorer&lt;/h2>
&lt;p>AWS Cost Explorer should be your first stop when analyzing costs. AWS Cost Explorer is a cost management tool that helps AWS users visualize, understand, and manage their AWS costs and usage. With Cost Explorer, users can analyze their AWS spending patterns and identify optimisation areas, helping reduce costs and increase efficiency.&lt;/p>
&lt;p>Tip: Inside cost explorer, you can group by usage type, often showing you the cause of hidden costs.&lt;/p>
&lt;h2 id="aws-budgets">AWS Budgets&lt;/h2>
&lt;p>Closely related to Cost Explorer is Budgets. AWS Budgets is a cost management tool that helps users set custom cost and usage budgets for their AWS resources, services, and accounts. With AWS Budgets, users can monitor their AWS spending and receive alerts when their usage or costs exceed the defined thresholds, helping to avoid unexpected expenses and optimize costs. This is vital for knowing that there is a problem ahead of time.&lt;/p>
&lt;h2 id="utilizing-saving-plans--reserved-instances">Utilizing Saving Plans &amp;amp; Reserved Instances&lt;/h2>
&lt;p>We can utilize Saving Plans and Reserved Instances to save costs on their AWS usage. Both options offer significant discounts compared to on-demand pricing but work slightly differently:&lt;/p>
&lt;p>Saving Plans offer flexible pricing for AWS compute usage compared to on-demand pricing. Users can commit to a specific dollar-per-hour usage rate for a one- or three-year term and then receive discounted rates for any usage that meets or exceeds the commitment. This allows users to save costs on a wide range of AWS services, including EC2, Fargate, Lambda, and more.&lt;/p>
&lt;p>Reserved Instances (RI) offer up to 75% savings compared to on-demand pricing for EC2 instances, RDS instances, and other services. Users can reserve capacity for a one or three-year term, and then receive discounted rates for the instances that match the reservation attributes. This allows users to save costs on predictable, steady-state workloads that run consistently over time.&lt;/p>
&lt;p>Depending on your workload and how your workload scales will ultimately be the driving force behind the decision to use either saving plans or reserved instances.&lt;/p>
&lt;h2 id="effectively-use-ecs-capacity-providers">Effectively use ECS Capacity Providers&lt;/h2>
&lt;p>ECS Capacity Providers allow users to define and manage groups of EC2 instances that can be used to run ECS tasks, with automatic scaling based on resource utilization and availability.&lt;/p>
&lt;p>Using Spot Instances as a scaling mechanism in ECS can further optimize costs and improve workload efficiency. Spot Instances are unused EC2 instances that can be rented at a significant discount compared to on-demand pricing. By using Spot Instances with ECS Capacity Providers, we can take advantage of these discounts while maintaining the desired availability and performance level.&lt;/p>
&lt;p>ECS can automatically manage the allocation of Spot Instances based on resource availability, helping to maximize cost savings while minimizing disruption to the workload.&lt;/p>
&lt;h2 id="switch-to-graviton-based-compute-instances">Switch to Graviton-based compute instances&lt;/h2>
&lt;p>In both EC2 and Lambda, we can switch over to Graviton based compute instances. They offer several benefits, including improved performance, cost efficiency, and reduced carbon footprint. Graviton is a custom-designed ARM-based processor optimized for AWS workloads, providing a high-performance, energy-efficient alternative to traditional x86-based instances.&lt;/p>
&lt;p>Your applications must be compatible with an ARM-based processor to take advantage of this, but you could receive up to 40%* savings depending on your workload.&lt;/p>
&lt;p>*From publically available sources&lt;/p>
&lt;h2 id="centralising-egress">Centralising Egress&lt;/h2>
&lt;p>One lesser-known tip is to centralise your egress. This involves creating a shared VPC that contains your NAT gateways and VPC Endpoints. These are two common costs in larger infrastructures that have many VPCs. There is a threshold that youâ€™ll need to breach before this approach delivers you cost savings, which is a combination of the following:&lt;/p>
&lt;ol>
&lt;li>How many NAT gateways do you have?&lt;/li>
&lt;li>How many VPC endpoints do you use in each VPC?&lt;/li>
&lt;/ol>
&lt;h2 id="reduce-log-ingestion">Reduce Log Ingestion&lt;/h2>
&lt;p>The last tip concerns log ingestion. If youâ€™re using AWS Cloudwatch to receive your logs, you might be paying too much for log ingestion. Iâ€™ve seen two common mistakes that lead to an increased cost:&lt;/p>
&lt;ol>
&lt;li>Duplicated logging. Teams may log directly to the Cloudwatch API, not realising that you already have ECS/Lambda capturing your logs.&lt;/li>
&lt;li>Logging too much: Teams may accidentally leave the log level set to verbose after diagnosing an issue, resulting in you ingesting much more than is necessary.&lt;/li>
&lt;/ol>
&lt;p>Both of these could easily increase your costs by 100s of dollars per month (if not more when talking about multiple environments), but itâ€™s often hidden by other costs such as lack of EC2 reserved instances.&lt;/p>
&lt;p>Also, set a retention policy or backup your logs to S3 storage for even more savings.&lt;/p>
&lt;p>This only begins to scratch the surface of AWS cost savings. In fact, entire companies are dedicated to saving people money on AWS. Let me know your cost-saving tips below!&lt;/p>
&lt;p>&lt;strong>ðŸ“£ Get the Weekly Newsletter Straight to Your Inbox! ðŸ“£&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 10 - Chaos Engineering on AWS</title><link>https://im5tu.io/article/2023/03/observed-no.-10-chaos-engineering-on-aws/</link><pubDate>Mon, 20 Mar 2023 01:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/03/observed-no.-10-chaos-engineering-on-aws/</guid><description>&lt;p>Welcome to the 10th edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at the practice of Chaos Engineering.&lt;/p>
&lt;h2 id="what-is-chaos-engineering">What is Chaos Engineering?&lt;/h2>
&lt;p>Chaos engineering is an innovative approach to testing and enhancing complex systems&amp;rsquo; reliability, resilience, and robustness. Born out of a need to ensure system stability in the face of unpredictable events, chaos engineering involves intentionally injecting faults, errors, and failures into a system to evaluate its behaviour and improve its ability to withstand such occurrences.&lt;/p>
&lt;h2 id="origins">Origins&lt;/h2>
&lt;p>The concept of chaos engineering originated at Netflix in the early 2010s. Netflix recognized the need to ensure the reliability of its services in the face of ever-increasing traffic and infrastructure complexity. They understood that traditional testing methods were insufficient for detecting and addressing potential issues in their intricate systems.&lt;/p>
&lt;p>To tackle this challenge, Netflix engineers developed the Chaos Monkey, the first tool in what would become the Simian Army. The Chaos Monkey was designed to randomly disable instances (virtual machines) within Netflix&amp;rsquo;s production environment, forcing the system to adapt and recover from these disruptions. This approach allowed engineers to observe the system&amp;rsquo;s behaviour under stress and identify weaknesses that could lead to outages or performance degradation. As a result, Netflix continuously improved their infrastructure and services, enhancing user experience and customer satisfaction.&lt;/p>
&lt;p>Over time, chaos engineering has evolved into a comprehensive discipline with principles and practices that extend beyond the Netflix ecosystem. Many organizations have adopted chaos engineering to test and improve their systems, ensuring they can withstand the unexpected and function smoothly in the face of adversity.&lt;/p>
&lt;h2 id="why-should-we-adopt-chaos-engineering">Why should we adopt chaos engineering?&lt;/h2>
&lt;p>Adopting chaos engineering offers several benefits that can improve the overall reliability, resilience, and performance of your systems, including:&lt;/p>
&lt;ol>
&lt;li>Proactive problem identification: Discover and address potential issues in your systems before they escalate into more significant problems or outages by intentionally injecting faults.&lt;/li>
&lt;li>Improved system resilience: Regularly conducting chaos engineering experiments help build more resilient systems that can withstand and recover from disruptions, such as hardware failures, software bugs, or spikes in traffic.&lt;/li>
&lt;li>Faster incident response: Develop better processes and practices by routinely dealing with simulated failures. Teams become more adept at identifying, diagnosing, and resolving issues, ultimately reducing the time it takes to recover from incidents.&lt;/li>
&lt;li>Enhanced understanding of system behaviour: Gain insights into how your systems behave under various conditions. This understanding can help you optimize your infrastructure, fine-tune performance, and improve resource allocation, resulting in a more efficient and cost-effective system.&lt;/li>
&lt;/ol>
&lt;h2 id="how-do-we-apply-this-in-aws">How do we apply this in AWS?&lt;/h2>
&lt;p>AWS offers the Fault Injection Simulator (FIS) as a managed service to help you implement chaos engineering principles in your infrastructure. FIS allows you to inject faults into your AWS resources and observe their behaviour, enabling you to identify and address potential issues that could affect the resilience of your applications. AWS FIS contains:&lt;/p>
&lt;ol>
&lt;li>Experiment Templates: These pre-configured templates define the fault injection actions and their target AWS resources. You can create custom templates or use the ones provided by AWS.&lt;/li>
&lt;li>Experiments: An experiment is an instance of an experiment template that runs in your environment. It consists of one or more actions that inject faults into your AWS resources.&lt;/li>
&lt;li>Actions: Actions are the specific fault injection tasks during an experiment. Examples include terminating instances, injecting latency, or throttling APIs.&lt;/li>
&lt;li>Stop Conditions: These are criteria that, when met, automatically halt an experiment. They help ensure the safety of your environment by preventing experiments from causing excessive damage or disruption.&lt;/li>
&lt;/ol>
&lt;p>To use AWS FIS, we need to follow a few steps:&lt;/p>
&lt;ol>
&lt;li>Define the scope of your experiment: Identify the AWS resources and services you want to target for fault injection. Consider the potential impact on your environment and ensure you have the necessary safeguards, such as backup systems and monitoring tools.&lt;/li>
&lt;li>Create an experiment template: Using the FIS console or API, create an experiment template that specifies the actions you want to perform and the resources they will target. You can use AWS-provided templates or create custom ones based on your requirements.&lt;/li>
&lt;li>Set up stop conditions: Define the criteria that will trigger the automatic termination of your experiment. For example, you can set a stop condition based on the duration of the experiment, the number of errors encountered, or a specific metric value.&lt;/li>
&lt;li>Run the experiment: Launch the experiment using the FIS console or API. Monitor the progress of the experiment in real-time using AWS monitoring tools such as Amazon CloudWatch or AWS X-Ray.&lt;/li>
&lt;li>Analyze the results: After completing the experiment, review the results to identify any weaknesses in your infrastructure or application. Use this information to develop and implement improvements that will enhance the resilience of your system.&lt;/li>
&lt;li>Iterate and refine: Chaos engineering is an ongoing process. Continuously run experiments with different fault injection scenarios to ensure your system remains resilient under various conditions.&lt;/li>
&lt;/ol>
&lt;p>As technology evolves rapidly, our reliance on distributed systems and related services has grown significantly. Chaos engineering emerges as a crucial practice, helping organizations ensure that their systems can adapt and recover from unforeseen challenges. I believe chaos engineering represents a paradigm shift in how we approach complex systems&amp;rsquo; reliability and resilience.&lt;/p>
&lt;p>By embracing a continuous learning and improvement culture, teams can better understand their systems, enhancing their ability to respond to incidents and deliver a consistent, high-quality user experience.&lt;/p>
&lt;p>Furthermore, the importance of chaos engineering is magnified by the potential consequences of system failures. Downtime and performance issues can have severe financial, operational, and reputational impacts on organizations. Businesses can mitigate these risks by investing in chaos engineering and ultimately protecting their bottom line.&lt;/p>
&lt;p>&lt;strong>ðŸ“£ Get the Weekly Newsletter Straight to Your Inbox! ðŸ“£&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 7 - Well Architected</title><link>https://im5tu.io/article/2023/02/observed-no.-7-well-architected/</link><pubDate>Mon, 27 Feb 2023 00:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/02/observed-no.-7-well-architected/</guid><description>&lt;p>Welcome to the seventh edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at the Well-Architected framework.&lt;/p>
&lt;h2 id="what-is-the-well-architected-framework">What is the Well-Architected Framework?&lt;/h2>
&lt;p>The Well-Architected Framework is a set of best practices and guidelines designed to help businesses build and operate reliable, secure, efficient, and cost-effective systems in the cloud. AWS conceived the framework to help customers evaluate their architecture and adopt best practices to improve their systems&amp;rsquo; performance, security, and scalability.&lt;/p>
&lt;p>The framework has six pillars, each focusing on a specific aspect of running on AWS. These are:&lt;/p>
&lt;ol>
&lt;li>Operational Excellence Pillar&lt;/li>
&lt;li>Security Pillar&lt;/li>
&lt;li>Reliability Pillar&lt;/li>
&lt;li>Performance Efficiency Pillar&lt;/li>
&lt;li>Cost Optimization Pillar&lt;/li>
&lt;li>Sustainability Pillar&lt;/li>
&lt;/ol>
&lt;h2 id="operational-excellence-pillar">Operational Excellence Pillar&lt;/h2>
&lt;p>The operational excellence pillar focuses on improving operating procedures and processes, monitoring systems, and continuously improving the overall operational capabilities of the organization. It provides best practices for managing change, responding to events and defining procedures to ensure consistent, repeatable processes are in place.&lt;/p>
&lt;h2 id="security-pillar">Security Pillar&lt;/h2>
&lt;p>The security pillar provides best practices for identifying and managing security risks, such as implementing strong access controls and enforcing least privilege principles. It also emphasizes the importance of automation of security tasks, continuous monitoring for security threats and maintaining compliance with security standards and regulations.&lt;/p>
&lt;h2 id="reliability-pillar">Reliability Pillar&lt;/h2>
&lt;p>The reliability pillar provides best practices for designing resilient systems, such as using distributed systems and redundancy to ensure high availability and implementing monitoring and alerting to quickly detect and respond to failures. It also emphasizes the importance of testing and validating system resilience to identify and address potential weaknesses before they impact users.&lt;/p>
&lt;h2 id="performance-efficiency-pillar">Performance Efficiency Pillar&lt;/h2>
&lt;p>The performance efficiency pillar provides best practices for selecting suitable instance types and sizes, using automation to scale resources up and down to meet demand, and optimizing application performance by leveraging caching, database performance tuning, and content delivery networks. It also emphasizes the importance of monitoring performance and usage metrics to identify areas for optimization and improvement.&lt;/p>
&lt;h2 id="cost-optimization-pillar">Cost Optimization Pillar&lt;/h2>
&lt;p>The cost optimization pillar provides best practices for selecting suitable pricing models, monitoring and analyzing usage data to identify opportunities for cost optimization, and implementing mechanisms for cost control, such as automated resource scheduling and usage quotas. It also emphasizes the importance of designing architectures that can scale cost-effectively by leveraging cloud services that offer pay-as-you-go pricing and dynamic resource allocation. By following the guidance of this pillar, organizations can optimize their cloud spending, reduce unnecessary costs, and maximize the value they get from their cloud investments.&lt;/p>
&lt;h2 id="sustainability-pillar">Sustainability Pillar&lt;/h2>
&lt;p>The sustainability pillar is the latest addition to the framework and focuses on designing and operating sustainable systems in the cloud. AWS introduced this pillar to minimize IT systems&amp;rsquo; environmental impact whilst reducing costs and downstream impacts.&lt;/p>
&lt;h2 id="are-you-well-architected">Are you well-architected?&lt;/h2>
&lt;p>You can assess your adherence to the AWS well-architected framework in two ways. The first option is to use an external consultancy company, which AWS can recommend partners for you. Typically these engagements are free to carry out the review but often come with an expectation that the consultancy would carry out some remediation work for you as a paid service. Some AWS partners may offer AWS credits for conducting the review.&lt;/p>
&lt;p>The second option is to run the assessment yourself in the AWS console, which is entirely free, using the AWS Well-Architected Tool. They have three different lenses at the time of writing:&lt;/p>
&lt;p>AWS Well-Architected Framework: The AWS Well-Architected Framework Lens provides foundational questions for you to consider for all your cloud architectures.&lt;/p>
&lt;p>Serverless Lens: The AWS Serverless Application Lens provides additional questions for you to consider for your serverless applications.&lt;/p>
&lt;p>SaaS Lens: The AWS SaaS Lens provides additional questions for you to consider for your Software-as-a-Service (SaaS) applications.&lt;/p>
&lt;p>AWS recommends enabling Trusted Advisor when you start the tool if you have access, as this will provide more context to your questions. The questions are relatively straightforward, but I&amp;rsquo;d recommend talking with your AWS account manager to see if they can provide some training for you and help you walk through the first one.&lt;/p>
&lt;p>You can run through the well-architected framework question in the AWS console using the AWS Well-Architected Tool: &lt;a href="https://eu-west-1.console.aws.amazon.com/wellarchitected/home">https://eu-west-1.console.aws.amazon.com/wellarchitected/home&lt;/a>&lt;/p>
&lt;p>Learn more about the Well-Architected framework here: &lt;a href="https://aws.amazon.com/architecture/well-architected">https://aws.amazon.com/architecture/well-architected&lt;/a>&lt;/p>
&lt;p>&lt;strong>ðŸ“£ Get the Weekly Newsletter Straight to Your Inbox! ðŸ“£&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Unlocking the best of AWS Route 53</title><link>https://im5tu.io/video/unlocking-the-best-of-aws-route-53/</link><pubDate>Sun, 26 Feb 2023 07:47:00 +0000</pubDate><guid>https://im5tu.io/video/unlocking-the-best-of-aws-route-53/</guid><description>&lt;p>In this video, I will show you the power of wildcards, health checks, and, my favourite, a Netflix-style multi-region DNS setup for scenarios on AWS Route 53. You&amp;rsquo;ll learn about the many capabilities of this service and how to use it to your advantage. Each section is accompanied by Terraform code. This video was originally was posted under DevOpsWithStu, but since then I have merged the channels together.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/oKyouRHsSVw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="video-links">Video Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=WDDkLOT8SCk">Netflix: Multi-Regional Resiliency and Amazon Route 53&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>How to Use AWS IAM Identity Centre with Terraform</title><link>https://im5tu.io/video/how-to-use-aws-iam-identity-centre-with-terraform/</link><pubDate>Sun, 26 Feb 2023 07:46:01 +0000</pubDate><guid>https://im5tu.io/video/how-to-use-aws-iam-identity-centre-with-terraform/</guid><description>&lt;p>This video will look at how to log in with AWS IAM Identity Centre and what to do when Terraform doesn&amp;rsquo;t work out of the box! Learn some of the inner mechanics behind AWS SSO Login. This video was originally was posted under DevOpsWithStu, but since then I have merged the channels together.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/CfA-pOQK8Fg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Observed No. 4 - Emerging Pattern: Centralised Ingress</title><link>https://im5tu.io/article/2023/01/observed-no.-4-emerging-pattern-centralised-ingress/</link><pubDate>Mon, 23 Jan 2023 02:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-4-emerging-pattern-centralised-ingress/</guid><description>&lt;p>Welcome to the fourth edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at a common pattern emerging across the industry: Centralised Ingress.&lt;/p>
&lt;h2 id="what-is-ingress-traffic">What is ingress traffic?&lt;/h2>
&lt;p>Ingress traffic refers to communication with your network from outside its perimeter. Typically when referring to ingress traffic, we talk about traffic from external consumers of our services, usually via HTTP or HTTPS. However, ingress could be any external traffic trying to hit our network. For example, it could be a Google search bot or an attacker trying to connect to our Redis cluster(s).&lt;/p>
&lt;h2 id="why-are-companies-centralising-ingress">Why are companies centralising ingress?&lt;/h2>
&lt;p>In the past, the companies implementing centralised ingress have been limited to large companies with tens of thousands of employees. As the technology improves and teams adopt more agile DevOps practices, companies as small as 50 people are implementing this pattern.&lt;/p>
&lt;p>To get a good understanding of why this is an emerging pattern, letâ€™s take a look at some of the benefits that companies will get by implementing a centralised ingestion layer:&lt;/p>
&lt;ol>
&lt;li>Improved security: Directing all incoming traffic to a central point can be more easily monitored for security threats, and any malicious traffic can be blocked before it reaches the internal network. Centralisation also reduces the total attack surface by keeping everything private, that should be private.&lt;/li>
&lt;li>Simplified network architecture: Directing all incoming traffic to a central point can simplify the overall network architecture and make it easier to understand and troubleshoot. The simplification may also lead to cost savings by reducing the total number of load balancers, depending on the final architecture.&lt;/li>
&lt;li>Additional functionality: Using a centralised ingestion point as a reverse proxy can provide other functionality like SSL termination, caching, rate limiting, and a starting point for tracing or authentication.&lt;/li>
&lt;/ol>
&lt;p>From what Iâ€™ve seen, companies tend to move towards a centralised point of ingestion primarily for security benefits, closely followed by the additional functionality they receive.&lt;/p>
&lt;p>Companies typically look at two main additional pieces of functionality:&lt;/p>
&lt;ol>
&lt;li>Rate limiting&lt;/li>
&lt;li>Tracing&lt;/li>
&lt;/ol>
&lt;p>Centralising the rate-limiting of all external clients in a centralised manner allows development teams to reduce the total complexity of their applications because they essentially offload the work to the point of ingress. Teams may still choose to have rate limiting for their internal clients, but the centralised view can provide rate limits that are not otherwise possible to implement in each application.&lt;/p>
&lt;p>With Tracing, a centralised ingress is the starting point for all requests regardless of destination. Apart from the standard benefits of having a distributed tracing system, one key benefit of starting the tracing at a single entry point is that you can generate metrics for every endpoint in your system, including any associated monitoring and alerting.&lt;/p>
&lt;h2 id="why-wouldnt-you-centralise-your-ingress">Why wouldnâ€™t you centralise your ingress?&lt;/h2>
&lt;p>Whilst there are a lot of positives of centralising your ingress traffic, there may be occasions where you shouldnâ€™t. These include:&lt;/p>
&lt;ol>
&lt;li>Scaling: Centralising your ingress traffic can create a bottleneck if the point of ingestion cannot handle a large amount of incoming traffic. This can lead to increased latency and decreased performance, or in some cases, a complete denial of service.&lt;/li>
&lt;li>Complexity: Centralising your ingress traffic can add complexity to the architecture, making it more difficult to understand and troubleshoot. Moreover, it can increase the risk of any deployments done to the ingestion layer, which must be managed accordingly.&lt;/li>
&lt;li>Limited flexibility: Centralising your ingress traffic can limit how traffic is directed and managed. It may be harder to implement more advanced routing rules or to route traffic to different services based on certain conditions.&lt;/li>
&lt;/ol>
&lt;p>As with any technology, the benefits and drawbacks need to be reviewed by your organisation against any requirements that they have. When deploying a centralised ingress layer, you also need to consider how many you will need to deploy because, ideally, you would have at least two different ingestion layersâ€”one for production and one for testing.&lt;/p>
&lt;p>If you want to see a video on deploying a centralised ingress network on AWS, please drop me a message or a comment.&lt;/p>
&lt;p>&lt;strong>ðŸ“£ Get the Weekly Newsletter Straight to Your Inbox! ðŸ“£&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 3 - Understanding Split Horizon DNS: How it works and How to Implement it in AWS</title><link>https://im5tu.io/article/2023/01/observed-no.-3-understanding-split-horizon-dns-how-it-works-and-how-to-implement-it-in-aws/</link><pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-3-understanding-split-horizon-dns-how-it-works-and-how-to-implement-it-in-aws/</guid><description>&lt;p>Welcome to the third edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at Split Horizon DNS.&lt;/p>
&lt;h2 id="what-is-split-horizon-dns">What is Split Horizon DNS?&lt;/h2>
&lt;p>Split Horizon DNS is a technique used in DNS to provide different responses to queries depending on where the query originates. For example, a DNS request originating from inside your network may elicit a different response to a DNS request from a consumer of your application.&lt;/p>
&lt;p>Splitting the responses by source can help ensure that only the resources which should be exposed to the internet are exposed. For example, an internal-only admin service would be an ideal candidate for not exposing to the internet, but we would want it addressable by our internal networks. In this case&lt;/p>
&lt;p>With Split Horizon DNS, each zone responds with an authoritative answer. For example, in a traditional DNS setup where the DNS is not split, there is only one authoritative answer - your primary DNS nameserver. With split DNS, your internal DNS will respond with one answer, and the external DNS will respond with another - typically for an internal and external load balancer, respectively.&lt;/p>
&lt;p>Split Horizon DNS is also known as Split View DNS, Split DNS or Split Brain DNS.&lt;/p>
&lt;h2 id="how-to-set-up-split-horizon-dns-in-aws">How to set up Split Horizon DNS in AWS?&lt;/h2>
&lt;p>To configure Split Horizon DNS, you perform the following steps:&lt;/p>
&lt;ol>
&lt;li>Create public and private hosted zones with the same name, for example: mydomain.com&lt;/li>
&lt;li>Associate one or more VPCs with the private hosted zone. Route 53 Resolver uses the private hosted zone to route DNS queries in the specified VPCs.&lt;/li>
&lt;li>Create records in each hosted zone. Records in the public-hosted zone control where internet traffic is routed, whilst records in the private-hosted zone control how traffic is routed internally.&lt;/li>
&lt;li>Query your DNS&lt;/li>
&lt;/ol>
&lt;p>If you have any questions or comments, please donâ€™t hesitate to contact me either in the comments, on Twitter or any medium listed on my website! Iâ€™d love to hear your thoughts. Subscribe to the newsletter below!&lt;/p>
&lt;p>&lt;strong>ðŸ“£ Get the Weekly Newsletter Straight to Your Inbox! ðŸ“£&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 1 - VPC Endpoint Policies</title><link>https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/</link><pubDate>Mon, 02 Jan 2023 01:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/</guid><description>&lt;p>Welcome to the very first edition of Observed! Each week I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at VPC endpoint policies in AWS.&lt;/p>
&lt;h2 id="what-are-vpc-endpoints">What Are VPC Endpoints?&lt;/h2>
&lt;p>VPC endpoints are network interfaces you can create in your VPC to enable communication between your VPC and other AWS services without using an Internet gateway, VPN, or VPC peering. VPC Endpoints allow you to secure and control access to both AWS services and your services by:&lt;/p>
&lt;p>Enabling access to AWS services from within your VPC without requiring a NAT gateway or VPN connection.&lt;/p>
&lt;p>Enabling private connectivity between your VPC and other AWS services, such as Amazon S3, Amazon SQS, and Amazon SNS allows you to keep your data and communication within the AWS network, improving security and reducing data transfer costs.&lt;/p>
&lt;p>Enabling access to AWS services from on-premises networks using AWS Direct Connect allows you to create a secure, private connection between your on-premises network and your VPC and then use VPC endpoints to access AWS services without going over the Internet.&lt;/p>
&lt;p>By default, VPC endpoints allow full access to the resources they are created for, so we need to add policies to guard against unwanted actions. For example, if you create a VPC endpoint for SQS, then the endpoint will allow any SQS traffic over the network. This is where VPC endpoint policies come into play.&lt;/p>
&lt;h2 id="vpc-endpoint-policies">VPC Endpoint Policies&lt;/h2>
&lt;p>One overlooked factor of VPC endpoints is the policies you can attach to them. VPC endpoint policies are an optional series of rules to control access to your VPC endpoint, which are attached to the endpoint itself rather than to an individual resource or service. Some common use cases for VPC endpoint policies include:&lt;/p>
&lt;p>Allowing only specific AWS accounts to access your VPC endpoint ensuring that only authorised users can access it.&lt;/p>
&lt;p>Allowing only specific IAM users or roles to access your VPC endpoint, which is useful for controlling access on a more granular level, allowing you to grant or deny access to individual IAM users or roles.&lt;/p>
&lt;p>Allowing only specific VPCs to access your VPC endpoint. This can be useful for limiting access to your VPC endpoint to only specific VPCs, such as VPCs that belong to your organisation.&lt;/p>
&lt;p>The policies themselves follow the standard IAM policy format, with the slight difference that you should only reference resources for the specific type of VPC endpoint. For example, don&amp;rsquo;t try to apply SNS permissions on an SQS VPC endpoint.&lt;/p>
&lt;p>Letâ€™s take a look at an example VPC endpoint policy:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Statement&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Sid&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;PreventUnintendedResourcesAndPrincipals&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Principal&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;*&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Action&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;s3:*&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Effect&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Deny&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Resource&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;*&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Condition&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;StringNotEquals&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;aws:ResourceOrgId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;o-XXXXXXX&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;aws:PrincipalOrgId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;o-XXXXXXX&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This policy prevents S3 usage outside the current organisation by using global conditional keys. When a principal makes a request to AWS, AWS gathers the request information into a request context. This request context is made available to you via the Condition element of the statement block in the policy document.&lt;/p>
&lt;p>The action section of the policy can either be wildcarded like I have in the example above, or you can limit it to specific actions such as s3:PutObject. When I create my policies, I try to use a combination of Effect:Deny and NotAction. I believe that being more specific about what actions are allowed on a VPC Endpoint leads to a better security posture.&lt;/p>
&lt;p>You can see which AWS services support VPC Endpoint Policies, and other valuable information, by using the describe-vpc-endpoint-services CLI command and checking for the field VpcEndpointPolicySupported in the response.&lt;/p>
&lt;p>I believe VPC Endpoint Policies are critical for securing infrastructure in sensitive environments, which is why they are part of my Well Architected Toolkit, which Iâ€™ll release later this year. Have you implemented VPC Endpoint Policies? What use cases have you found for them? Let me know how you use them below or reach out to me on &lt;a href="https://twitter.com/codewithstu">Twitter&lt;/a>.&lt;/p>
&lt;p>&lt;strong>ðŸ“£ Get the Weekly Newsletter Straight to Your Inbox! ðŸ“£&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>AWS Timestream &amp; .NET - Underrated?</title><link>https://im5tu.io/video/aws-timestream-net-underrated/</link><pubDate>Fri, 21 Oct 2022 06:45:00 +0100</pubDate><guid>https://im5tu.io/video/aws-timestream-net-underrated/</guid><description>&lt;p>Let&amp;rsquo;s look at how to use AWS Timestream in .NET. Timestream is a managed time series database from AWS. Itâ€™s fast and scalable, with advanced features like scheduled queries.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/NA6LXzTu4Q4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="video-links">Video Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://docs.aws.amazon.com/timestream/latest/developerguide/getting-started.db-w-sample-data.html">AWS Timestream Sample Data&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/awslabs/amazon-timestream-tools/tree/mainline/sample_apps/dotnet">Amazon Timestream .NET Samples&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Live: Serverless SaaS</title><link>https://im5tu.io/video/live-serverless-saas/</link><pubDate>Thu, 01 Sep 2022 09:44:15 +0100</pubDate><guid>https://im5tu.io/video/live-serverless-saas/</guid><description>&lt;p>In this session, I&amp;rsquo;m going to build out a design for a serverless SaaS solution on AWS. This takes into account things like budgetting and technology choices. The aim will be to to deploy a regionally independent solution.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/cxZ2HllKUg0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Live AWS System Design: Payments Gateway</title><link>https://im5tu.io/video/live-aws-system-design-payments-gateway/</link><pubDate>Thu, 18 Aug 2022 10:08:30 +0100</pubDate><guid>https://im5tu.io/video/live-aws-system-design-payments-gateway/</guid><description>&lt;p>In this session, we are going to design a typically Payments Gateway that you would be expected to design as part of the hiring process for a FinTech. We will about some of the considerations to take into account when facing this question in a systems design interview.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/cSetznf9CWA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Live: AWS Multi-Account Structure Design</title><link>https://im5tu.io/video/live-aws-multi-account-structure-design/</link><pubDate>Thu, 11 Aug 2022 09:20:59 +0100</pubDate><guid>https://im5tu.io/video/live-aws-multi-account-structure-design/</guid><description>&lt;p>In this session, we are going to design an AWS Multi-Account structure and the networking behind it. We will learn how to connect different accounts together and some of the considerations to take into account when facing this question in a systems design interview.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/DxxtGEekhJY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Live: Systems Design - Stock Tick API</title><link>https://im5tu.io/video/live-systems-design-stock-tick-api/</link><pubDate>Thu, 04 Aug 2022 09:36:49 +0100</pubDate><guid>https://im5tu.io/video/live-systems-design-stock-tick-api/</guid><description>&lt;p>In this session, we are going to design a fairly typical stock trading API. We are going to go through some of the considerations that you need to have as well as looking at some of the curve balls that you may face. This will help you design distributed systems and data intensive applications using an event driven architecture.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/jSSsRMD3RUY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Extending the AWS SDK for .NET</title><link>https://im5tu.io/video/extending-the-aws-sdk-for-net/</link><pubDate>Sat, 08 Jan 2022 23:07:05 +0000</pubDate><guid>https://im5tu.io/video/extending-the-aws-sdk-for-net/</guid><description>&lt;p>In this video weâ€™re taking a look at how to extend the AWS SDK for .NET, which can be useful for various tasks like adding in some custom observability components into the request pipeline. This article is a companion resource for the video linked above in case you prefer a written version. Iâ€™m actively using the approach described here to implement distributed tracing for all my AWS calls.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/oHXFG7G5bCo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="video-links">Video Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://im5tu.io/article/2022/01/extending-the-aws-sdk-for-.net/">Corresponding Blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Extending the AWS SDK for .Net</title><link>https://im5tu.io/article/2022/01/extending-the-aws-sdk-for-.net/</link><pubDate>Sat, 08 Jan 2022 08:00:00 +0000</pubDate><guid>https://im5tu.io/article/2022/01/extending-the-aws-sdk-for-.net/</guid><description>&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/oHXFG7G5bCo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>In this article we&amp;rsquo;re taking a look at how to extend the AWS SDK for .NET, which can be useful for various tasks like adding in some custom observability components into the request pipeline. This article is a companion resource for the video linked above in case you prefer a written version. I&amp;rsquo;m actively using the approach described here to implement distributed tracing with OpenTelemetry for all AWS calls at work.&lt;/p>
&lt;h2 id="our-example">Our Example&lt;/h2>
&lt;p>To demonstrate how to extend the AWS SDK, we are going to have a very simple application that simply lists all of the DynamoDB instances registered in the target system:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// NuGet Package Reference: &amp;lt;PackageReference Include=&amp;#34;AWSSDK.DynamoDBv2&amp;#34; Version=&amp;#34;3.7.2.4&amp;#34; /&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Amazon.DynamoDBv2;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Amazon.Runtime;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> Amazon.Runtime.Internal;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> var client = &lt;span style="color:#66d9ef">new&lt;/span> AmazonDynamoDBClient(&lt;span style="color:#66d9ef">new&lt;/span> AmazonDynamoDBConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ServiceURL = &lt;span style="color:#e6db74">&amp;#34;http://localhost:4566&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> table &lt;span style="color:#66d9ef">in&lt;/span> (&lt;span style="color:#66d9ef">await&lt;/span> client.ListTablesAsync()).TableNames)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Found: &amp;#34;&lt;/span> + table);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In order to run the above example, you need to have a working &lt;a href="https://im5tu.io/article/2022/09/pro-testing-with-xunit-localstack/">localstack&lt;/a> instance running with one or more DynamoDB tables created. If you want to copy the files that I&amp;rsquo;ve used, you can view them in the &lt;a href="#appendix">appendix&lt;/a> below. If you&amp;rsquo;re using my files, then you should see the following when you run the program:&lt;/p>
&lt;p>&lt;img src="initial-output.jpg" alt="Output before customization">&lt;/p>
&lt;h2 id="customizing-the-request-pipeline">Customizing the request pipeline&lt;/h2>
&lt;p>There are three parts to getting our code injected into the AWS request pipeline:&lt;/p>
&lt;ol>
&lt;li>Telling the AWS SDK about our pipeline customizer&lt;/li>
&lt;li>Creating a new instance of &lt;code>IRuntimePipelineCustomizer&lt;/code>&lt;/li>
&lt;li>Creating a new instance of &lt;code>IPipelineHandler&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>Although the &lt;code>IRuntimePipelineCustomizer&lt;/code> is in the internal namespace, this should be relatively stable to use as this is the same technique that AWS use themselves to extend the SDK. Just note, as an internal interface, you&amp;rsquo;ll want to ensure that everything continues to work when upgrading.&lt;/p>
&lt;h3 id="the-entrypoint-into-the-aws-sdk">The entrypoint into the AWS SDK&lt;/h3>
&lt;p>The AWS SDK provides an extensibility point inside of the &lt;code>Amazon.Runtime.Internal&lt;/code> namespace called &lt;code>RuntimePipelineCustomizerRegistry&lt;/code>. I discovered this entrypoint by looking at the code for AWS X-Ray. This type is a singleton that allows you to register a class that customizes a pipeline. We are interested in a method called &lt;code>Register&lt;/code> that takes an instance of &lt;code>IRuntimePipelineCustomizer&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>RuntimePipelineCustomizerRegistry.Instance.Register(&lt;span style="color:#66d9ef">new&lt;/span> AWSPipelineCustomization());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> var client = &lt;span style="color:#66d9ef">new&lt;/span> AmazonDynamoDBClient(&lt;span style="color:#66d9ef">new&lt;/span> AmazonDynamoDBConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ServiceURL = &lt;span style="color:#e6db74">&amp;#34;http://localhost:4566&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> table &lt;span style="color:#66d9ef">in&lt;/span> (&lt;span style="color:#66d9ef">await&lt;/span> client.ListTablesAsync()).TableNames)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Found: &amp;#34;&lt;/span> + table);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It&amp;rsquo;s super important that you register your pipeline customization as early as possible so that you can capture all AWS SDK calls.&lt;/p>
&lt;h3 id="creating-an-instance-of-iruntimepipelinecustomizer">Creating an instance of IRuntimePipelineCustomizer&lt;/h3>
&lt;p>Once registered, an instance of &lt;code>IRuntimePipelineCustomizer&lt;/code> will be called every time a new pipeline is created. The type that we need to implement is pretty trivial to implement as it&amp;rsquo;s main purpose is to add one or more pipeline handlers:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">AWSPipelineCustomization&lt;/span> : IRuntimePipelineCustomizer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> UniqueName { &lt;span style="color:#66d9ef">get&lt;/span>; } = nameof(AWSPipelineCustomization);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Customize(Type type, RuntimePipeline pipeline)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (!&lt;span style="color:#66d9ef">typeof&lt;/span>(AmazonServiceClient).IsAssignableFrom(type))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pipeline.AddHandlerAfter&amp;lt;EndpointResolver&amp;gt;(&lt;span style="color:#66d9ef">new&lt;/span> AWSPipelineHandler());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We first check to see whether the type that&amp;rsquo;s passed in is assignable to an AmazonServiceClient so that we can safely ignore types that are invalid such as mock types.&lt;/p>
&lt;p>To add our &lt;code>IPipelineHandler&lt;/code> instance, we need to call one of three methods:&lt;/p>
&lt;ol>
&lt;li>&lt;code>AddHandler&lt;/code> - Adds to the end of the pipeline&lt;/li>
&lt;li>&lt;code>AddHandlerBefore&lt;/code> - Adds before the specified handler type&lt;/li>
&lt;li>&lt;code>AddHandlerAfter&lt;/code> - Adds after the specified handler type&lt;/li>
&lt;/ol>
&lt;p>Generally speaking you want to add your handler after the &lt;code>EndpointResolver&lt;/code> so that you catch all retry attempts and any credential based calls, such as IAM instance metadata.&lt;/p>
&lt;h3 id="creating-our-ipipelinehandler">Creating our IPipelineHandler&lt;/h3>
&lt;p>When are implementing the &lt;code>IPipelineHandler&lt;/code>, we have two choices: implement the interface directly for maximum control or inherit from the class &lt;code>PipelineHandler&lt;/code> &lt;em>(recommended)&lt;/em> and override just the methods that we need. We&amp;rsquo;re not going to do anything fancy in our implementation here, except record the AWS SDK call to the console window:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">AWSPipelineHandler&lt;/span> : PipelineHandler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> Task&amp;lt;T&amp;gt; InvokeAsync&amp;lt;T&amp;gt;(IExecutionContext executionContext)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Executing: &amp;#34;&lt;/span> + executionContext.RequestContext.RequestName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">base&lt;/span>.InvokeAsync&amp;lt;T&amp;gt;(executionContext);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> InvokeSync(IExecutionContext executionContext)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Console.WriteLine(&lt;span style="color:#e6db74">&amp;#34;Executing: &amp;#34;&lt;/span> + executionContext.RequestContext.RequestName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">base&lt;/span>.InvokeSync(executionContext);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When you combine all of the code, you should receive an output similar to the following:&lt;/p>
&lt;p>&lt;img src="final-output.jpg" alt="Output after customization">&lt;/p>
&lt;p>The instance of &lt;code>IExecutionContext&lt;/code> that you are passed contains both the request and (eventually) the response object, plus other useful information like the invocation id and whether the last exception is one that can be retried or not.&lt;/p>
&lt;p>That&amp;rsquo;s it for this article, I hope that you find this extension point useful for your own code base!&lt;/p>
&lt;h2 id="appendix">Appendix&lt;/h2>
&lt;p>You can also view the files on my &lt;a href="https://github.com/Im5tu/videos/tree/main/TipsAndTricks/8%20-%20Extending%20the%20AWS%20SDK">Videos Github Repository&lt;/a>.&lt;/p>
&lt;h3 id="docker-compose-file">Docker Compose File&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;3.5&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">localstack&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">localstack/localstack:0.12.12&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restart&lt;/span>: &lt;span style="color:#ae81ff">always&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;4566:4566&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">localstack&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">HOSTNAME_EXTERNAL=localstack&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">SERVICES=dynamodb&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">DEFAULT_REGION=eu-north-1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">AWS_ACCESS_KEY_ID=xxx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">AWS_SECRET_ACCESS_KEY=xxx&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">AWS_DEFAULT_REGION=eu-north-1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./scripts/init.sh:/docker-entrypoint-initaws.d/init.sh&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="localstack-init-script">Localstack init script&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">#Make sure this file is saved with LF line endings (not CRLF)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#Open this file in VSCode and look in the bottom right corner&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>set -x
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aws dynamodb create-table &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --table-name test &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --attribute-definitions AttributeName&lt;span style="color:#f92672">=&lt;/span>Key,AttributeType&lt;span style="color:#f92672">=&lt;/span>S AttributeName&lt;span style="color:#f92672">=&lt;/span>Code,AttributeType&lt;span style="color:#f92672">=&lt;/span>S &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --key-schema AttributeName&lt;span style="color:#f92672">=&lt;/span>Key,KeyType&lt;span style="color:#f92672">=&lt;/span>HASH AttributeName&lt;span style="color:#f92672">=&lt;/span>Code,KeyType&lt;span style="color:#f92672">=&lt;/span>RANGE &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --provisioned-throughput ReadCapacityUnits&lt;span style="color:#f92672">=&lt;/span>10,WriteCapacityUnits&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --endpoint-url http://localstack:4566
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>AWS Architecture Design - Global Lifts Scenario</title><link>https://im5tu.io/video/aws-architecture-design-global-lifts-scenario/</link><pubDate>Thu, 04 Feb 2021 18:30:09 +0000</pubDate><guid>https://im5tu.io/video/aws-architecture-design-global-lifts-scenario/</guid><description>&lt;p>Ever wondered how to answer the architecture design questions in interviews? If so, this video is for you. I take a sample of what I often receive as an architecture test and walk through how I would design the architecture on AWS explaining each design decision on the way - often with notes about the technology capabilities along the way. We will also go through some common questions that are often thrown in as curve balls during the process - including how to prevent them through efficient design.&lt;/p>
&lt;p>Nothing in this video is scripted or prepared in anyway, just the scenario, the camera (which died) and my thoughts. Please do your own research on the techniques presented here before you implement them in your architectures to make sure you have a real understanding of how it all works.&lt;/p>
&lt;p>If you like this video and want to see more like this, or have a scenario you would like me to cover, please let me know in the comments below and we can explore new scenarios together :)&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube-nocookie.com/embed/xd_TElOedew" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="video-links">Video Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/api-gateway/features/">API Gateway&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/lambda/features/">Lambda functions&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.InitialThroughput">DynamoDB pre-provisioning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/dynamodb/global-tables/">DynamoDB Global Table&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/#:~:text=DynamoDB%20Streams%20is%20a%20powerful,for%20up%20to%2024%20hours.">DynamoDB Streams&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://towardsdatascience.com/delivering-real-time-streaming-data-to-amazon-s3-using-amazon-kinesis-data-firehose-2cda5c4d1efe">Kinesis Firehose to S3&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/global-accelerator/features/">Global Accelerator&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Using Certificates From AWS Private Certificate Authority in .NET</title><link>https://im5tu.io/article/2021/01/using-certificates-from-aws-private-certificate-authority-in-.net/</link><pubDate>Sun, 17 Jan 2021 11:43:01 +0000</pubDate><guid>https://im5tu.io/article/2021/01/using-certificates-from-aws-private-certificate-authority-in-.net/</guid><description>&lt;p>As more and more companies get hacked, there is a strong resurgence in the community for the desire to have TLS for everything, everywhere. There are many valuable projects, tools and resources, such as &lt;a href="https://letsencrypt.org/">LetsEncrypt&lt;/a> available to help both individuals &amp;amp; companies secure their resources. One of those tools is AWS Private Certificate Authority.&lt;/p>
&lt;p>Traditionally, running a private certificate authority has been costly but this paradigm has changed with the advent of free certificate authorities and cloud-based offerings. But why would we want to run our own still? One of the main reasons is that some networks are private in nature, much like the majority of banking networks, and clouds like AWS will not issue certificates for private networks unless you have your own AWS Private Certificate Authority instance.&lt;/p>
&lt;h2 id="what-is-aws-private-certificate-authority">What is AWS Private Certificate Authority?&lt;/h2>
&lt;p>AWS Private Certificate Authority provides you a highly-available private Certificate Authority service without the ongoing maintenance costs of operating your own private Certificate Authority. It extends ACMâ€™s certificate management capabilities to both public and private certificates. AWS Private Certificate Authority allows developers to be more agile by providing them APIs to create and deploy private certificates programmatically. You also have the flexibility to create private certificates for applications that require custom certificate lifetimes or resource names. With ACM Private Certificate Authority, you can create and manage private certificates for your connected resources in one place with a secure, pay as you go, managed private Certificate Authority service. &lt;em>&lt;a href="https://aws.amazon.com/certificate-manager/private-certificate-authority/">Source&lt;/a>.&lt;/em>&lt;/p>
&lt;h2 id="exporting-a-certificate-from-aws-private-certificate-authority">Exporting a certificate from AWS Private Certificate Authority&lt;/h2>
&lt;p>This article assumes that you already have a certificate issued from your Private Certificate Authority and you have the ARN available. There are a few different that we need to implement to our certificate loader:&lt;/p>
&lt;ol>
&lt;li>A class that&amp;rsquo;s going to load certificates from AWS PCA ACM;&lt;/li>
&lt;li>A instance of &lt;code>IPasswordFinder&lt;/code> so that BouncyCastle can read the exported PEM file;&lt;/li>
&lt;li>A few handy &lt;a href="https://im5tu.io/article/2012/12/extension-methods-in-dotnet/">extension methods&lt;/a> for hooking up the exported certificate with Kestrel&lt;/li>
&lt;/ol>
&lt;p>In order to export and read the certificates, we are going to need to install the following packages:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;ItemGroup&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;AWSSDK.CertificateManager&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;3.3.101.48&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Portable.BouncyCastle&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;1.8.6&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;/ItemGroup&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We are going to be using &lt;code>AWSSDK.CertificateManager&lt;/code> to export the certificate from AWS Private Certificate Authority and &lt;code>Portable.BouncyCastle&lt;/code> to read the exported PEM file, turning it into a &lt;code>X509Certificate2&lt;/code> that we can push into the Kestrel webserver. First, we are going to create our interface which will allow us to swap out the implementation later for testing purposes, should that be desired:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ICertificateAuthorityLoader&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Task&amp;lt;X509Certificate2&amp;gt; LoadCertificateAsync(&lt;span style="color:#66d9ef">string&lt;/span> certificateArn);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next, we have the implementation itself:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">DefaultCertificateAuthorityLoader&lt;/span> : ICertificateAuthorityLoader
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> IAmazonCertificateManager _certificateManager;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> DefaultCertificateAuthorityLoader() : &lt;span style="color:#66d9ef">this&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> AmazonCertificateManagerClient())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> DefaultCertificateAuthorityLoader(IAmazonCertificateManager certificateManager)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _certificateManager = certificateManager;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">async&lt;/span> Task&amp;lt;X509Certificate2&amp;gt; LoadCertificateAsync(&lt;span style="color:#66d9ef">string&lt;/span> certificateArn)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> pwd = Guid.NewGuid().ToString(&lt;span style="color:#e6db74">&amp;#34;N&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">using&lt;/span> var passphrase = &lt;span style="color:#66d9ef">new&lt;/span> MemoryStream(Encoding.UTF8.GetBytes(pwd));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Get the certificate from PCA&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> exportedCert = &lt;span style="color:#66d9ef">await&lt;/span> _certificateManager.ExportCertificateAsync(&lt;span style="color:#66d9ef">new&lt;/span> ExportCertificateRequest
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CertificateArn = certificateArn,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Passphrase = passphrase
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">byte&lt;/span>[] certBytes = Encoding.ASCII.GetBytes(exportedCert.Certificate);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> cert = &lt;span style="color:#66d9ef">new&lt;/span> X509Certificate2(certBytes, pwd);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Ensure that the private key is loaded&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> privateKey = DecodePrivateKey(exportedCert.PrivateKey, pwd);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert = cert.CopyWithPrivateKey(DotNetUtilities.ToRSA(privateKey.rsaPrivatekey));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> cert;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> (AsymmetricCipherKeyPair keyPair, RsaPrivateCrtKeyParameters rsaPrivatekey) DecodePrivateKey(&lt;span style="color:#66d9ef">string&lt;/span> encryptedPrivateKey, &lt;span style="color:#66d9ef">string&lt;/span> password)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TextReader textReader = &lt;span style="color:#66d9ef">new&lt;/span> StringReader(encryptedPrivateKey);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> PemReader pemReader = &lt;span style="color:#66d9ef">new&lt;/span> PemReader(textReader, &lt;span style="color:#66d9ef">new&lt;/span> PasswordFinder(password));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">object&lt;/span> privateKeyObject = pemReader.ReadObject();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> RsaPrivateCrtKeyParameters rsaPrivatekey = (RsaPrivateCrtKeyParameters)privateKeyObject;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> RsaKeyParameters rsaPublicKey = &lt;span style="color:#66d9ef">new&lt;/span> RsaKeyParameters(&lt;span style="color:#66d9ef">false&lt;/span>, rsaPrivatekey.Modulus, rsaPrivatekey.PublicExponent);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> AsymmetricCipherKeyPair kp = &lt;span style="color:#66d9ef">new&lt;/span> AsymmetricCipherKeyPair(rsaPublicKey, rsaPrivatekey);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (kp, rsaPrivatekey);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>LoadCertificateAsync&lt;/code> method is the primary workhorse for exporting the certificate. We generate a random GUID, which could be swapped out for a more secure method, as a temporary password as one will need to be supplied when we call the AWS Private Certificate Authority API. This password is then added to the &lt;code>ExportCertificateRequest&lt;/code> that we generate before we request that the certificate is exported. There are a couple of points where this could fail:&lt;/p>
&lt;ul>
&lt;li>We didn&amp;rsquo;t supply a password&lt;/li>
&lt;li>The certificate is unavailable&lt;/li>
&lt;li>The certificate was not issued by an AWS Private Certificate Authority. This is probably going to be the most common case in my experience. Only AWS Private Certificate Authority issued certificates can be exported with the private key, which is needed to load the certificate into Kestrel&lt;/li>
&lt;/ul>
&lt;p>Asuming that our request was successful, we have a property called &lt;code>Certificate&lt;/code> which we can pass straight into a new &lt;code>X509Certificate2&lt;/code> instance. This &lt;strong>does not&lt;/strong> contain the private key, so we need to use BouncyCastle to parse the private key from a secondary property on the response object, which is fortunately called &lt;code>PrivateKey&lt;/code>. As this primary key is secured, we need to use BouncyCastle&amp;rsquo;s &lt;code>PemReader&lt;/code> in order to read the private key, supplying the password via an instance of &lt;code>IPasswordFinder&lt;/code>, which you can see below. From here, it can then be converted to an &lt;code>AsymmetricCipherKeyPair&lt;/code>. Finally, we can use the &lt;code>CopyWithPrivateKey&lt;/code> to create a new instance of the &lt;code>X509Certificate2&lt;/code> certificate, but this time with the private key. This can then be loaded into Kestrel to secure web requests.&lt;/p>
&lt;p>For completeness, here is the implementation of &lt;code>IPasswordFinder&lt;/code> that I used which simply converts the plaintext password into a char array:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">PasswordFinder&lt;/span> : IPasswordFinder
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> _password;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> PasswordFinder(&lt;span style="color:#66d9ef">string&lt;/span> password)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _password = password;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">char&lt;/span>[] GetPassword()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> _password.ToCharArray();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally, we have a series of &lt;a href="https://im5tu.io/article/2012/12/extension-methods-in-dotnet/">extension methods&lt;/a> that allow us to hook up our application in various ways. There&amp;rsquo;s not too much to explain here, as this is hooking up our code above with the Kestrel webserver:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">/// Extensions for configuration of a Kestrel Web Server&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">HostingExtensions&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// Loads a certificate from a Private Certificate Authority instance, based on ARN.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> IWebHostBuilder UseHttpsCertificateFromPCA(&lt;span style="color:#66d9ef">this&lt;/span> IWebHostBuilder builder, IConfiguration configuration, IAmazonCertificateManager? certificateManagerClient = &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> builder.ConfigureKestrel(server =&amp;gt; server.UseHttpsCertificateFromPCA(configuration, certificateManagerClient));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> builder;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// Loads a certificate from a Private Certificate Authority instance, based on ARN.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> IWebHostBuilder UseHttpsCertificateFromPCA(&lt;span style="color:#66d9ef">this&lt;/span> IWebHostBuilder builder, &lt;span style="color:#66d9ef">string&lt;/span> arnOrEnvironmentVar, IAmazonCertificateManager? certificateManagerClient = &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> builder.ConfigureKestrel(server =&amp;gt; server.UseHttpsCertificateFromPCA(arnOrEnvironmentVar, certificateManagerClient));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> builder;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// Loads a certificate from a Private Certificate Authority instance, based on ARN.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> KestrelServerOptions UseHttpsCertificateFromPCA(&lt;span style="color:#66d9ef">this&lt;/span> KestrelServerOptions options, IConfiguration configuration, IAmazonCertificateManager? certificateManagerClient = &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> options.UseHttpsCertificateFromPCA(configuration.GetValue&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt;(&lt;span style="color:#e6db74">&amp;#34;CertificateArn&amp;#34;&lt;/span>), certificateManagerClient);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// Loads a certificate from a Private Certificate Authority instance, based on ARN.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> KestrelServerOptions UseHttpsCertificateFromPCA(&lt;span style="color:#66d9ef">this&lt;/span> KestrelServerOptions options, &lt;span style="color:#66d9ef">string&lt;/span> arnOrEnvironmentVar, IAmazonCertificateManager? certificateManagerClient = &lt;span style="color:#66d9ef">null&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#66d9ef">string&lt;/span>.IsNullOrWhiteSpace(arnOrEnvironmentVar))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> ArgumentNullException(nameof(arnOrEnvironmentVar));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (!arnOrEnvironmentVar.StartsWith(&lt;span style="color:#e6db74">&amp;#34;arn:&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> arn = Environment.GetEnvironmentVariable(arnOrEnvironmentVar);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#66d9ef">string&lt;/span>.IsNullOrWhiteSpace(arnOrEnvironmentVar))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> ArgumentException(&lt;span style="color:#e6db74">$&amp;#34;Cannot load the details of the arn from the environment variable &amp;#39;{arnOrEnvironmentVar}&amp;#39;. Please check the environment variable is set and is not null, empty or whitespace.&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (arn?.StartsWith(&lt;span style="color:#e6db74">&amp;#34;arn:&amp;#34;&lt;/span>) != &lt;span style="color:#66d9ef">true&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> ArgumentException(&lt;span style="color:#e6db74">&amp;#34;The specified arn was loaded from the environment variable but does not meet the required format&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> arnOrEnvironmentVar = arn;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Yes async in sync method sucks, but the client only has a async method on it...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> certificate = (certificateManagerClient &lt;span style="color:#66d9ef">is&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span> ? &lt;span style="color:#66d9ef">new&lt;/span> DefaultCertificateAuthorityLoader() : &lt;span style="color:#66d9ef">new&lt;/span> DefaultCertificateAuthorityLoader(certificateManagerClient)).LoadCertificateAsync(arnOrEnvironmentVar).Result;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> options.UseHttpsCertificate(certificate);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// Configures the kestrel web server with the specified certificate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> IWebHostBuilder UseHttpsCertificate(&lt;span style="color:#66d9ef">this&lt;/span> IWebHostBuilder builder, X509Certificate2 certificate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> builder.ConfigureKestrel(server =&amp;gt; server.UseHttpsCertificate(certificate));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> builder;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// Configures the kestrel web server with the specified certificate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">/// &amp;lt;/summary&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> KestrelServerOptions UseHttpsCertificate(&lt;span style="color:#66d9ef">this&lt;/span> KestrelServerOptions options, X509Certificate2 certificate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> options.ConfigureHttpsDefaults(o =&amp;gt; o.ServerCertificate = certificate);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> options;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Unfortunately, the configuration above does rely on the use of asynchronous invocation in a synchronous context, which we can&amp;rsquo;t do too much about because of the differences between the SDK and the way Kestrel is built. Our usage of the extensions is as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> IHostBuilder CreateHostBuilder(&lt;span style="color:#66d9ef">string&lt;/span>[] args) =&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Host.CreateDefaultBuilder(args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .ConfigureWebHostDefaults(webBuilder =&amp;gt; {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> webBuilder.UseStartup&amp;lt;Startup&amp;gt;()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .UseHttpsCertificateFromPCA(&lt;span style="color:#e6db74">&amp;#34;arn:aws:acm:eu-west-1:**************:certificate/**********&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>or:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> IHostBuilder CreateHostBuilderAlt(&lt;span style="color:#66d9ef">string&lt;/span>[] args) =&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Host.CreateDefaultBuilder(args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .ConfigureWebHostDefaults(webBuilder =&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> webBuilder.ConfigureKestrel((context, options) =&amp;gt; options.UseHttpsCertificateFromPCA(context.Configuration))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .UseStartup&amp;lt;Startup&amp;gt;();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After this, you should be able to use a certificate from AWS Private Certificate Authority inside your application. Enjoy!&lt;/p></description></item><item><title>Publish Metrics to Cloudwatch in .NET Core</title><link>https://im5tu.io/article/2020/12/publish-metrics-to-cloudwatch-in-.net-core/</link><pubDate>Sun, 13 Dec 2020 16:21:58 +0000</pubDate><guid>https://im5tu.io/article/2020/12/publish-metrics-to-cloudwatch-in-.net-core/</guid><description>&lt;p>In a &lt;a href="https://im5tu.io/article/2020/01/diagnostics-in-.net-core-3-event-counters/">previous post&lt;/a> I took a look at how we can utilize .NET event counters to record metrics in our applications. However, I never covered the implementation of how I write the metrics to either CloudWatch or DataDog. In this article, I&amp;rsquo;m going to take a look at how to publish metrics to CloudWatch and one way of integrating it with the aforementioned blog series.&lt;/p>
&lt;h2 id="what-is-cloudwatch">What is CloudWatch?&lt;/h2>
&lt;p>Amazon CloudWatch is a monitoring and observability service that provides you with data and actionable insights to monitor your applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. CloudWatch collects monitoring and operational data in the form of logs, metrics, and events, providing you with a unified view of AWS resources, applications, and services that run on AWS and on-premises servers. You can use CloudWatch to detect anomalous behaviour in your environments, set alarms, visualize logs and metrics side by side, take automated actions, troubleshoot issues, and discover insights to keep your applications
running smoothly. &lt;em>(&lt;a href="https://aws.amazon.com/cloudwatch/">Source&lt;/a>)&lt;/em>&lt;/p>
&lt;h2 id="writing-a-cloudwatch-metric-publisher">Writing a CloudWatch Metric Publisher&lt;/h2>
&lt;p>If you&amp;rsquo;ve been following the previous articles, you would have seen that I omitted the type that I personally use to pass the metric information to the publishers. The common metric update type I&amp;rsquo;ve been using contains the name of the metric, it&amp;rsquo;s value and any tags/dimensions that you which to be attached to the metric. For completeness, and incase you haven&amp;rsquo;t been following the previous articles, here is the &lt;code>MetricUpdate&lt;/code> type that we will reference:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">[DebuggerDisplay(&amp;#34;{ToString(),nq}&amp;#34;)]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> &lt;span style="color:#a6e22e">MetricUpdate&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> IEnumerable&amp;lt;KeyValuePair&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>,&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt;&amp;gt; Tags;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> Name;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">float&lt;/span> Value;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> MetricUpdate(&lt;span style="color:#66d9ef">string&lt;/span> name, &lt;span style="color:#66d9ef">float&lt;/span> &lt;span style="color:#66d9ef">value&lt;/span>, IEnumerable&amp;lt;KeyValuePair&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>,&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt;&amp;gt; tags)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Name = name;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Value = &lt;span style="color:#66d9ef">value&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Tags = tags;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> ToString() =&amp;gt; &lt;span style="color:#e6db74">$&amp;#34;{Name}:{Value} ({string.Join(&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;, Tags.Select(x =&amp;gt; $&amp;#34;&lt;/span>{x.Key}={x.Value}&lt;span style="color:#e6db74">&amp;#34;))})&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once we have this type configured, we need to install the &lt;code>AWSSDK.CloudWatch&lt;/code> NuGet package, which will allow us to communicate with AWS CloudWatch. Our entry point to publishing the metrics will be a simple interface that will enable us to swap out the implementation for testing at a later point:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">ICloudWatchMetricsPublisher&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Task PublishMetricsAsync(IEnumerable&amp;lt;MetricUpdate&amp;gt; metrics);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We will also need to have a corresponding implementation for the &lt;code>ICloudWatchMetricsPublisher&lt;/code> contract:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">CloudWatchMetricsPublisher&lt;/span> : ICloudWatchMetricsPublisher
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> ILogger&amp;lt;CloudWatchMetricsPublisher&amp;gt; _logger;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> CloudWatchMetricsPublisher(ILogger&amp;lt;CloudWatchMetricsPublisher&amp;gt; logger)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _logger = logger ?? &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> ArgumentNullException(nameof(logger));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">async&lt;/span> Task PublishMetricsAsync(IEnumerable&amp;lt;MetricUpdate&amp;gt; metrics)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">using&lt;/span> var client = CreateClient();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> datums = &lt;span style="color:#66d9ef">new&lt;/span> List&amp;lt;MetricDatum&amp;gt;(metrics.Select(ConvertToDatum));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> request = &lt;span style="color:#66d9ef">new&lt;/span> PutMetricDataRequest
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Namespace = &lt;span style="color:#e6db74">&amp;#34;MyCustomNamespace&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> MetricData = datums
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> client.PutMetricDataAsync(request);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> AmazonCloudWatchClient CreateClient() =&amp;gt; &lt;span style="color:#66d9ef">new&lt;/span> AmazonCloudWatchClient();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Other methods, defined below&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Our main steps in the code above are:&lt;/p>
&lt;ol>
&lt;li>Create a new instance of the &lt;code>AmazonCloudWatchClient&lt;/code> class which allows us to communicate with CloudWatch&lt;/li>
&lt;li>Convert our &lt;code>MetricUpdate&lt;/code> type into the AWS specific &lt;code>MetricDatum&lt;/code> type&lt;/li>
&lt;li>Create a new instance of &lt;code>PutMetricDataRequest&lt;/code> and call &lt;code>PutMetricDataAsync&lt;/code> on the AWS Client, which sends the metrics through to CloudWatch, assuming we have the correct permissions&lt;/li>
&lt;/ol>
&lt;p>When we convert our &lt;code>MetricUpdate&lt;/code> to a &lt;code>MetricDatum&lt;/code>, there are a few points that we need to consider, including:&lt;/p>
&lt;ul>
&lt;li>The unit type that we want to be represented for the metric in CloudWatch&lt;/li>
&lt;li>The storage resolution that we want to use&lt;/li>
&lt;li>The number of dimensions that we can use for the metric&lt;/li>
&lt;/ul>
&lt;p>I&amp;rsquo;ve wrapped up some of this logic into a &lt;code>ConvertToDatum&lt;/code> method to keep the logic contained and the main publishing code clear:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> MetricDatum ConvertToDatum(&lt;span style="color:#66d9ef">in&lt;/span> MetricUpdate metric)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> MetricDatum
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TimestampUtc = DateTime.UtcNow,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> MetricName = metric.Name,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Value = metric.Value,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Unit = GetUnitMapping(metric),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StorageResolution = &lt;span style="color:#ae81ff">1&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Dimensions = FormatDimensions(metric.Tags)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> };
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The most important point part about the code snippet above is the &lt;code>StorageResolution&lt;/code>. Setting this to 1 specifies this metric as a high-resolution metric, so that CloudWatch stores the metric with sub-minute resolution down to one second. Setting this to 60 specifies this metric as a regular-resolution metric, which CloudWatch stores at 1-minute resolution. For more information about high-resolution metrics, see &lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html#high-resolution-metrics">High-Resolution Metrics&lt;/a> in the Amazon CloudWatch User Guide.&lt;/p>
&lt;p>Otherwise, for clarity and future extensibility, I&amp;rsquo;ve separated the unit mapping and the dimensions formatting. Lastly, should you want to change the timestamp, you just need to update the &lt;code>MetricUpdate&lt;/code> type to add the TimeStamp. This could be handy for retries or delays in publication, but that&amp;rsquo;s out of scope for this article. Now, lets take a look at the unit mapping code:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> StandardUnit GetUnitMapping(&lt;span style="color:#66d9ef">in&lt;/span> MetricUpdate metric)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (metric.Name.EndsWith(&lt;span style="color:#e6db74">&amp;#34;latency&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> StandardUnit.Milliseconds;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (metric.Name.EndsWith(&lt;span style="color:#e6db74">&amp;#34;count&amp;#34;&lt;/span>) || metric.Name.EndsWith(&lt;span style="color:#e6db74">&amp;#34;length&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> StandardUnit.Count;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (metric.Name.EndsWith(&lt;span style="color:#e6db74">&amp;#34;usage&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> StandardUnit.Percent;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (metric.Name.EndsWith(&lt;span style="color:#e6db74">&amp;#34;size&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> StandardUnit.Bytes;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (metric.Name.EndsWith(&lt;span style="color:#e6db74">&amp;#34;rate&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> StandardUnit.CountSecond;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> StandardUnit.None;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There&amp;rsquo;s nothing really special going on here, we just use the ending of the metric to decide what . In my real production code, this is configurable should we need to explicitly set something, but i&amp;rsquo;ll leave that as an exercise for you dearest reader.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">private&lt;/span> List&amp;lt;Dimension&amp;gt; FormatDimensions(IEnumerable&amp;lt;KeyValuePair&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#66d9ef">string&lt;/span>&amp;gt;&amp;gt; dimensions)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> result = &lt;span style="color:#66d9ef">new&lt;/span> List&amp;lt;Dimension&amp;gt;(&lt;span style="color:#ae81ff">10&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> dimension &lt;span style="color:#66d9ef">in&lt;/span> dimensions)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result.Add(&lt;span style="color:#66d9ef">new&lt;/span> Dimension
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Name = dimension.Key,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Value = dimension.Value
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// We can only support a maximum of 10 dimensions in cloudwatch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (result.Count == &lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _logger.LogWarning(&lt;span style="color:#e6db74">&amp;#34;Cloudwatch only supports 10 dimensions per metric. Any additional dimensions have been removed.&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> result;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> result;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, there is nothing really special going on with the formatting of the dimensions. It is important to note that only the first 10 elements of the collection will be passed through to CloudWatch. This is a limitation on the CloudWatch side and as such, we log a warning to know when we&amp;rsquo;ve hit that limit, allowing us to act on it in the future should we need to. As far as the publishing is concerned, that&amp;rsquo;s pretty much it.&lt;/p>
&lt;p>&lt;em>As you may have noticed from the snippets of code, I have left out a lot of the configuration that would normally be done as I didn&amp;rsquo;t want to bloat the code with unnecessary code, allowing you to get the important bits.&lt;/em>&lt;/p>
&lt;h2 id="integrating-our-cloudwatch-publisher-with-net-event-counters">Integrating our CloudWatch publisher with .NET Event Counters&lt;/h2>
&lt;p>In a &lt;a href="https://im5tu.io/article/2020/01/diagnostics-in-.net-core-3-event-counters/">previous post&lt;/a> I received a comment asking how I hook up .NET EventCounters with either DataDog or CloudWatch. The short answer is that I use the above code, at least a variation of it, to publish directly to CloudWatch. The longer answer is that I have an extensible mechanism which allows me to publish to one or more sources at once, depending on my needs. To do this, we need multiple parts to complete the puzzle:&lt;/p>
&lt;ol>
&lt;li>An observable which we can publish the metric updates to&lt;/li>
&lt;li>An observer per publisher (eg: CloudWatch/DataDog)&lt;/li>
&lt;li>The publishing code (like the former part of this article)&lt;/li>
&lt;li>Link the .NET EventCounters collectors to the observable&lt;/li>
&lt;/ol>
&lt;h3 id="creating-the-observable-infrastructure">Creating the observable infrastructure&lt;/h3>
&lt;p>The first part of linking .NET event counters to our new publishers, is to create an implementation of the observable pattern for which .NET has two handy interfaces that we can use:&lt;/p>
&lt;ul>
&lt;li>&lt;code>IObservable&amp;lt;T&amp;gt;&lt;/code> - which allows us to subscribe to a stream of events that are emitted by an object&lt;/li>
&lt;li>&lt;code>IObserver&amp;lt;T&amp;gt;&lt;/code> - which can be added to the above observable via the &lt;code>Subscribe&lt;/code> method. The instance that&amp;rsquo;s subscribed will receive notifications for: each object in the stream, exceptions from the stream and completion of the stream.&lt;/li>
&lt;/ul>
&lt;p>As the &lt;code>IObservable&amp;lt;T&amp;gt;&lt;/code> interface isn&amp;rsquo;t concerned with how the data is retrieved from the stream, as it could be from a network stream or an in-memory stream for example, we will need a way of publishing the data. To do this, we will add the &lt;code>WriteMetric&lt;/code> method to a custom interface so that we can implement the pattern properly:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">interface&lt;/span> &lt;span style="color:#a6e22e">IMetricsObservable&lt;/span> : IObservable&amp;lt;MetricUpdate&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">void&lt;/span> WriteMetric(&lt;span style="color:#66d9ef">ref&lt;/span> MetricUpdate metricUpdate);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">MetricsObservable&lt;/span> : IMetricsObservable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> List&amp;lt;IObserver&amp;lt;MetricUpdate&amp;gt;&amp;gt; _observers;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> MetricsObservable(IEnumerable&amp;lt;IObserver&amp;lt;MetricUpdate&amp;gt;&amp;gt; observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _observers = observers.ToList();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> IDisposable Subscribe(IObserver&amp;lt;MetricUpdate&amp;gt; observer)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">lock&lt;/span> (_observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _observers.Add(observer);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> ActOnDispose(() =&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">lock&lt;/span> (_observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _observers.Remove(observer);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> });
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> WriteMetric(&lt;span style="color:#66d9ef">ref&lt;/span> MetricUpdate metricUpdate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">lock&lt;/span>(_observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> observer &lt;span style="color:#66d9ef">in&lt;/span> _observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observer.OnNext(metricUpdate);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Dispose()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">lock&lt;/span> (_observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> observer &lt;span style="color:#66d9ef">in&lt;/span> _observers)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observer.OnCompleted();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _observers.Clear();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">ActOnDispose&lt;/span> : IDisposable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> Action _act;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> _disposed = &lt;span style="color:#66d9ef">false&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> ActOnDispose(Action act)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _act = act;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Dispose()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_disposed)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _disposed = &lt;span style="color:#66d9ef">true&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _act();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The code above is a basic implementation of the observable pattern, which also takes a series of known consumers from an IoC container should it be configured. We return a custom disposable from the &lt;code>Subscribe&lt;/code> method, that when disposed, will remove the &lt;code>IObserver&amp;lt;T&amp;gt;&lt;/code> instance from the list of known consumers.&lt;/p>
&lt;p>The next part of the puzzle is to create our &lt;code>IObserver&amp;lt;T&amp;gt;&lt;/code> implementation. We want the processing of this element to be lightning fast as we will hold up the stream if we try do asynchronous processing, especially since the contract of &lt;code>IObserver&amp;lt;T&amp;gt;&lt;/code> does not support asynchronicity. To work around this, we are going to use &lt;code>System.Threading.Channels&lt;/code> to write to a temporary channel and pick this up in a background service that can do the aggregation of the metrics before publishing. I strongly recommend that you read &lt;a href="https://www.stevejgordon.co.uk/an-introduction-to-system-threading-channels">Steve Gordons excellent introduction to System.Threading.Channels&lt;/a> for background on this subject:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">CloudwatchMetricObserver&lt;/span> : IObserver&amp;lt;MetricUpdate&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> ChannelWriter&amp;lt;MetricUpdate&amp;gt; _channel;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> CloudwatchMetricObserver(ChannelWriter&amp;lt;MetricUpdate&amp;gt; channel)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _channel = channel;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnCompleted() { }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnError(Exception error) { }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnNext(MetricUpdate &lt;span style="color:#66d9ef">value&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _channel.TryWrite(&lt;span style="color:#66d9ef">value&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>By proxying the metrics through a channel, we have a unique ability to batch the data in our requests through a simple pattern in the background service. The rough flow is:&lt;/p>
&lt;ul>
&lt;li>Check to see if there is an element in the channel. If an element is present:
&lt;ul>
&lt;li>Add it to a temporary list of metrics&lt;/li>
&lt;li>If we have hit the capacity of our temporary storage, publish the metrics&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>If no element in the channel:
&lt;ul>
&lt;li>Publish any remaining metrics (eg: if we haven&amp;rsquo;t hit the capacity)&lt;/li>
&lt;li>Wait for the stop signal or an element to appear in the channel, whichever is first&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>This flow is what I&amp;rsquo;ve implemented below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">CloudwatchPublishingService&lt;/span> : BackgroundService
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> ICloudWatchMetricsPublisher _publisher;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> ILogger&amp;lt;CloudwatchPublishingService&amp;gt; _logger;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> ChannelReader&amp;lt;MetricUpdate&amp;gt; _metricReader;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">readonly&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> _capacity = &lt;span style="color:#ae81ff">20&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> List&amp;lt;MetricUpdate&amp;gt;? _metrics;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> CloudwatchPublishingService(ICloudWatchMetricsPublisher publisher,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ILogger&amp;lt;CloudwatchPublishingService&amp;gt; logger,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ChannelReader&amp;lt;MetricUpdate&amp;gt; metricReader)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _publisher = publisher;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _logger = logger;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _metricReader = metricReader;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">async&lt;/span> Task ExecuteAsync(CancellationToken cancellationToken)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">async&lt;/span> Task PublishAsync()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_metrics &lt;span style="color:#66d9ef">is&lt;/span> {} &amp;amp;&amp;amp; _metrics.Count &amp;gt; &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> _publisher.PublishMetricsAsync(_metrics);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Ensure that we reset the metric container after publishing&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _metrics = &lt;span style="color:#66d9ef">null&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> (!cancellationToken.IsCancellationRequested)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">try&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_metricReader.TryRead(&lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> metric))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// We don&amp;#39;t want to make API requests on every metric as this will cost a bucket load and is horribly inefficient&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _metrics ??= &lt;span style="color:#66d9ef">new&lt;/span> List&amp;lt;MetricUpdate&amp;gt;(_capacity);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _metrics.Add(metric);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (_metrics.Count &amp;gt;= _capacity)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> PublishAsync();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> PublishAsync();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">await&lt;/span> _metricReader.WaitToReadAsync(cancellationToken);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">catch&lt;/span> (OperationCanceledException) when (cancellationToken.IsCancellationRequested)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">catch&lt;/span> (Exception exception)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _logger.LogError(exception, exception.Message);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the code above, we&amp;rsquo;ve explicitly set the capacity of our temporary storage to 20, as this is the limitation imposed on us by the CloudWatch &lt;code>PutMetricData&lt;/code> endpoint. For those familiar with System.Threading.Channels, I have explicitly chosen not to use the &lt;code>IAsyncEnumerable&lt;/code> support so that I have more control over the batching, ie: I don&amp;rsquo;t have to wait for a complete batch of 20 metrics before I send the request the data be stored in CloudWatch. This can help with terminal scenarios where you may be able to get additional metrics out before the service dies, and when there are long intervals between metrics being published.&lt;/p>
&lt;p>The last piece of the puzzle is to link the &lt;code>MetricsCollectionService&lt;/code> from the &lt;a href="https://im5tu.io/article/2020/01/diagnostics-in-.net-core-3-event-counters/#processing-events">previous article&lt;/a> (some parts removed for brevity) with the &lt;code>IMetricsObservable&lt;/code> we&amp;rsquo;ve just created:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">internal&lt;/span> &lt;span style="color:#66d9ef">sealed&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">MetricsCollectionService&lt;/span> : EventListener, IHostedService
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">private&lt;/span> IMetricsObservable _metricsObservable;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> MetricsCollectionService(IMetricsObservable metricsObservable)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _metricsObservable = metricsObservable ?? &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> ArgumentNullException(nameof(metricsObservable));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">protected&lt;/span> &lt;span style="color:#66d9ef">override&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> OnEventWritten(EventWrittenEventArgs eventData)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (eventData.EventName != &lt;span style="color:#e6db74">&amp;#34;EventCounters&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> || eventData.Payload.Count &amp;lt;= &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> || !(eventData.Payload[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#66d9ef">is&lt;/span> IDictionary&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#66d9ef">object&lt;/span>&amp;gt; data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> || !data.TryGetValue(&lt;span style="color:#e6db74">&amp;#34;CounterType&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> counterType)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> || !data.TryGetValue(&lt;span style="color:#e6db74">&amp;#34;Name&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> name))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> metricType = counterType.ToString();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">float&lt;/span> metricValue = &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#e6db74">&amp;#34;Sum&amp;#34;&lt;/span>.Equals(metricType) &amp;amp;&amp;amp; data.TryGetValue(&lt;span style="color:#e6db74">&amp;#34;Increment&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> increment))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metricValue = Convert.ToSingle(increment);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#e6db74">&amp;#34;Mean&amp;#34;&lt;/span>.Equals(metricType) &amp;amp;&amp;amp; data.TryGetValue(&lt;span style="color:#e6db74">&amp;#34;Mean&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> mean))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metricValue = Convert.ToSingle(mean);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> metric = &lt;span style="color:#66d9ef">new&lt;/span> MetricUpdate(metricName, metricValue, tags);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _metricsObservable.WriteMetric(&lt;span style="color:#66d9ef">ref&lt;/span> metric);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Naturally, if you don&amp;rsquo;t need the flexibility of adding multiple destinations, then you can bypass some of the code that I&amp;rsquo;ve shown above and go direct to the publisher instead of through the &lt;code>IMetricsObservable&lt;/code> indirection.&lt;/p>
&lt;p>That&amp;rsquo;s it for this article, I hope you&amp;rsquo;ve learned how we can publish metrics to CloudWatch in C# and how we can link this with our &lt;a href="http://localhost:1313/series/diagnostics-in-.net-core-3/">previous work&lt;/a> on .NET Event Counters. Happy Metrics Collection!&lt;/p></description></item><item><title>Building a Zero Trust Architecture In AWS</title><link>https://im5tu.io/article/2020/12/building-a-zero-trust-architecture-in-aws/</link><pubDate>Sat, 05 Dec 2020 15:38:58 +0000</pubDate><guid>https://im5tu.io/article/2020/12/building-a-zero-trust-architecture-in-aws/</guid><description>&lt;p>In the vast majority of companies that I&amp;rsquo;ve been in, software engineering &amp;amp; infrastructure best practises have often been left as something that needs to be updated later because building the product comes first. This is completely understandable as if you don&amp;rsquo;t have a product, you don&amp;rsquo;t have employment. This presents problems later when companies are beginning to scale rapidly and become popular. Not only does the company becomes a target for malicious actors, but security-related incidents can easily occur by leaving storage devices open accidentally. Once a malicious actor is in your system, you usually have pretty big problems unless you design your architectures with Zero Trust in mind.&lt;/p>
&lt;h2 id="what-is-a-zero-trust-architecture">What is a Zero Trust Architecture&lt;/h2>
&lt;p>Zero trust means many different things to many different people, but the concept has its origins in Network Security. A Zero Trust Architecture aims to remove any source of inherent trust from the network, treat it as hostile and instead gain confidence that you can trust a connection through techniques like authentication and encryption. Zero Trust Architectures form a part of a more well-rounded defense in depth strategy.&lt;/p>
&lt;p>The path to a fully Zero Trust Architecture is a long one, which you may argue is never complete because infrastructure rarely becomes stagnant and are always evolving. It&amp;rsquo;s important to recognise that moving to this style of architecture can be time-consuming and you should do so with care and plenty of testing before removing any existing control infrastructure. The following principals are a combination of some of the recommendations from national security bodies, AWS best practises and best practises that I consider important. This is not intended to be an exhaustive list, but form part of your research or provide a basic understanding.&lt;/p>
&lt;h2 id="zero-trust-architecture-principals">Zero Trust Architecture Principals&lt;/h2>
&lt;p>Here are the principals that we are going to cover:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#authentication--authorization-everywhere">Authentication &amp;amp; Authorization Everywhere&lt;/a>&lt;/li>
&lt;li>&lt;a href="#limit-the-scope-of-permissions">Limit the scope of permissions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#encryption-at-rest--in-transit">Encryption At-Rest &amp;amp; In-Transit&lt;/a>&lt;/li>
&lt;li>&lt;a href="#prefer-managed-services">Prefer Managed Services&lt;/a>&lt;/li>
&lt;li>&lt;a href="#vpc-subnet-isolation--endpoints">VPC Subnet Isolation &amp;amp; Endpoints&lt;/a>&lt;/li>
&lt;li>&lt;a href="#use-transit-gateway-to-connect-vpcs">Use Transit Gateway to connect VPCs&lt;/a>&lt;/li>
&lt;li>&lt;a href="#choose-standards-where-possible">Choose Standards Where Possible&lt;/a>&lt;/li>
&lt;li>&lt;a href="#store-secrets-securely">Store secrets securely&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="authentication--authorization-everywhere">Authentication &amp;amp; Authorization Everywhere&lt;/h3>
&lt;p>As mentioned earlier, part of the zero-trust model is not to trust anything by removing inherent trust. Authentication ensures that the requester is who they say they are, whereas authorization gives the requester access to resources.&lt;/p>
&lt;p>Authentication everywhere means that we ensure that users, services and devices are successfully authenticated before performing any actions. Once authenticated, the entry point for each action checks the authorization of the user to ensure that they have the relevant permissions to perform the action. Frameworks like Asp.NET Core make this easy through the use of code-based policies in the identity framework.&lt;/p>
&lt;p>Cloud providers typically have a robust identity and access management (IAM) system in place which removes the need to store credentials in services. Instead, credentials are derived from the service context and are authenticated on each request. If possible, avoid storing the credentials of a service that you need to access and favour service roles that have permissions to access the resources, leveraging the cloud providers IAM infrastructure. You can see the &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">AWS IAM Security Best Practises Here&lt;/a>.&lt;/p>
&lt;p>For users in your organization, one easy to add protection layer is to ensure multi-factor authentication (MFA) is enabled for the services that support it. Typically this is added to authentication systems to prevent malicious actions when a password is compromised. In addition, some cloud providers and services allow you to enforce MFA when deleting or changing resources, preventing damaging actions for an already authenticated user.&lt;/p>
&lt;h3 id="limit-the-scope-of-permissions">Limit the scope of permissions&lt;/h3>
&lt;p>One of the tendencies when building out services is to give a service full administration privileges, usually when troubleshooting or initial development. Unfortunately, it is common to see that these elevated permissions are left in-place when troubleshooting has completed and the service is running as normal. Instead, start with a minimum set of permissions and grant additional permissions as necessary - without going to full administration privileges from the start. Doing so is more secure than starting with permissions that are too lenient and then trying to tighten them later. This is also known as the principal of least privilege.&lt;/p>
&lt;p>An example of this would be a reporting service. Typically, a reporting service does not have a requirement to write data to a database, only to extract and present to the user. In a zero-trust model, we would create a unique login for the reporting service and limit it&amp;rsquo;s access to only those database entries it requires. We would also ensure that the user is a read-only user so if the service is compromised then a malicious actor cannot insert or alter any of the data stored in the database.&lt;/p>
&lt;p>AWS supports permissions boundaries for IAM entities (users or roles). A permissions boundary is an advanced feature for using a managed policy to set the maximum permissions that an identity-based policy can grant to an IAM entity. An entity&amp;rsquo;s permissions boundary allows it to perform only the actions that are allowed by both its identity-based policies and its permissions boundaries. Add IAM users into IAM Roles to make the management role-based rather than elevating individual users. With role-based permissions, you should limit the scope to only the permissions that are required for the role the users fulfil, exactly like we do with services. With multiple teams, the permissions should be limited to the infrastructure components that the team manages. For example, do not give access to all DynamoDB instances.&lt;/p>
&lt;p>For organizations, you can investigate the use of a service control policy (SCP). Service control policies are a type of organization policy that you can use to manage permissions in your organization. SCP&amp;rsquo;s offer central control over the maximum available permissions for all accounts in your organization. SCP&amp;rsquo;s alone are not sufficient to granting permissions to the accounts in your organization. No permissions are granted by an SCP. An SCP defines a guardrail, or sets limits, on the actions that the account&amp;rsquo;s administrator can delegate to the IAM users and roles in the affected accounts.&lt;/p>
&lt;p>Here is an example of a limited IAM policy: &lt;img src="iam-policy.png" alt="Limited IAM Policy for SNS">&lt;/p>
&lt;p>You can read more about &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html">AWS IAM Policy Boundaries here&lt;/a> and &lt;a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html">Service Control Policies here&lt;/a>.&lt;/p>
&lt;h3 id="encryption-at-rest--in-transit">Encryption At-Rest &amp;amp; In-Transit&lt;/h3>
&lt;p>Over the past couple of years, we&amp;rsquo;ve seen a massive movement towards securing websites with certificates and ensuring that all traffic is sent via HTTPS. Protocols like &lt;a href="https://letsencrypt.org/docs/client-options/">ACME&lt;/a> and &lt;a href="https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html">HSTS&lt;/a> help ensure that implementation of HTTPS is easy, cheaper and consistent. Unfortunately, the security story usually ends there for most organizations unless there is a regulatory reason. We need to consider both Encryption At Rest and Encryption In-Transit.&lt;/p>
&lt;p>Encryption In-Transit refers to the encryption that&amp;rsquo;s applied to data as it transits from one system to another. For the web, this is often seen as HTTPS but Encryption In-Transit includes any data that is sent over the network meaning that we need to take a look at all the protocols we use like web sockets, AMQP and SQL. It is often possible to use a TLS based connection to meet this part of the principal. Using TLS everywhere doesn&amp;rsquo;t guarantee the service is authenticated, just that the connection is secured and it hasn&amp;rsquo;t be changed inflight. You may consider implementing &lt;a href="https://www.docusign.com/blog/dsdev-mutual-tls-stuff-know">mutual TLS&lt;/a> (or MTLS) for additional authentication requirements.&lt;/p>
&lt;p>Encryption At Rest refers to the encryption that&amp;rsquo;s applied to data when it is persisted to disk. When building out infrastructure, engineers tend to only think about data storage areas like DynamoDB, S3 and SQL Server as places that they need to have encryption at rest. When looking at the architecture holistically, we need to consider a lot more which often requires digging into provider-specific documentation to find the answers. Here are a few examples from AWS, where data can be persisted on disk for the purposes of retries and reliability:&lt;/p>
&lt;p>&lt;strong>SQS&lt;/strong>&lt;/p>
&lt;p>In-transit encryption is provided, but you must opt-in to at-rest encryption: &lt;img src="sqs-encryption.png" alt="SQS Encryption">&lt;/p>
&lt;p>&lt;strong>SNS&lt;/strong>&lt;/p>
&lt;p>In-transit encryption is provided, but you must opt-in to at-rest encryption: &lt;img src="sns-encryption.png" alt="SNS Encryption">&lt;/p>
&lt;p>By performing end to end encryption both at rest and in-transit, we often meet any regulatory needs such as PCI and GDPR compliance. In the UK, the Information Commissioner&amp;rsquo;s Office can now issue fines of up to 4% of a company&amp;rsquo;s annual turnover, or 20 million (whichever is greater) for the worst data offences - so this is something that we should always be considering.&lt;/p>
&lt;h3 id="prefer-managed-services">Prefer Managed Services&lt;/h3>
&lt;p>Another common pattern that I see is the use of custom-built services where a suitable managed service exists. A classic example of this is SQL database servers. Most cloud providers have managed service offerings which look after key parts of the platform like patching of the OS, replication and more. Moreover, they usually implement the best security practises, or at least offer them as a useable template. The chances are you&amp;rsquo;re like me and not an expert in configuring these systems, so it&amp;rsquo;s best to leave it to the professionals unless we have a legitimate case for managing it ourselves. Even then, we need to challenge all the aspects of the self-hosted use case to ensure that it fits we our desired security profile.&lt;/p>
&lt;h3 id="vpc-subnet-isolation--endpoints">VPC Subnet Isolation &amp;amp; Endpoints&lt;/h3>
&lt;p>Most cloud providers allow you to isolate your compute resources into a separate area, called a Virtual Private Cloud (VPC). You can easily customize the network configuration of your VPC. You can assign a CIDR range and configure your subnets in accordance with your business requirements. There are four types of subnets that you should consider implementing:&lt;/p>
&lt;ul>
&lt;li>Public subnets: Anything that should be internet accessible, eg: NAT Gateways, Bastion hosts etc&lt;/li>
&lt;li>Private subnets: Accessible from the public subnets. Has access to database &amp;amp; intra subnets. Able to talk to the internet.&lt;/li>
&lt;li>Database subnets: Only accessible from private and intra subnets. Typically no internet access available to instances.&lt;/li>
&lt;li>Intra subnets: Services that access resources that live inside of the VPC and require no internet access. AWS resources will require a &lt;a href="https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/">VPC Endpoint&lt;/a> to work.&lt;/li>
&lt;/ul>
&lt;p>Even when inside of a VPC in AWS, it is a little known fact that your traffic to AWS services will traverse via the public internet. The solution to this is &lt;a href="https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/">VPC Endpoints&lt;/a>. A &lt;a href="https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/">VPC Endpoint&lt;/a> enables private connections between your VPC and supported AWS services and &lt;a href="https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/">VPC Endpoint&lt;/a> services powered by AWS PrivateLink. AWS PrivateLink is a technology that enables you to privately access services by using private IP addresses. Traffic between your VPC and the other service does not leave the Amazon network. A &lt;a href="https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/">VPC Endpoint&lt;/a> does not require an internet gateway, virtual private gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service.&lt;/p>
&lt;p>For serverless architectures, we may be utilizing Lambdas for the scaling capabilities it can provide. A Lambda may execute outside of a VPC entirely, as shown in the picture below. This means it would by-pass any protections that you have inside of your VPC. I would personally recommend that all functions are isolated into their own subnets inside of your VPC.&lt;/p>
&lt;p>&lt;img src="lambda-vpc.png" alt="Lambda VPC">&lt;/p>
&lt;h3 id="use-transit-gateway-to-connect-vpcs">Use Transit Gateway to connect VPCs&lt;/h3>
&lt;p>In AWS, you can configure a transit gateway to route internal traffic between VPCs. AWS Transit Gateway can be configured with or without route propagation. It&amp;rsquo;s advised to explicitly set the associations between your VPCs so that you know what connects to what. This forms part of the know your network and services that the National Cyber Security Centre advises. An example of how to set this up using terraform can be found &lt;a href="https://medium.com/driven-by-code/aws-transit-gateway-routing-in-multiple-accounts-713b10ca7b34">here&lt;/a>.&lt;/p>
&lt;p>A secondary advantage of using transit gateway is that it has a robust monitoring solution in-place. This is vital for a zero-trust architecture because you need to know and understand your network. You may also define a network access control list (NACL) as an optional layer of security.&lt;/p>
&lt;h3 id="choose-standards-where-possible">Choose Standards Where Possible&lt;/h3>
&lt;p>Whenever possible, use standards-based technologies. This allows interoperability between devices and services. A good example of which is authentication and authorization, where common standards such as OpenID Connect, OAuth or SAML allow you to use a single directory service to authenticate to many services. Moreover, when you are (re)implementing something that already exists, you are likely missing the thousands of peer-reviews that typically happens for widely adopted standards. You are also not going to get any on-going support either from standards bodies or the surrounding communities. If there are tool chains in your organization, try to standardize on them. For example, if you have a toolchain for authentication, use the same toolchain everywhere and ensure that it is consistently configured through the use of packages (ie: NPM/NuGet packages).&lt;/p>
&lt;h3 id="store-secrets-securely">Store secrets securely&lt;/h3>
&lt;p>Occasionally, we will have configuration settings that need to be kept secret, these will often change on a per-environment basis. A typical approach would be to use Octopus Deploy&amp;rsquo;s variables to keep these values secure and then deploy a new task definition with the variables set as environment variables on the task definitions. This represents a number of problems as the values are stored in plain text in the task definition and available on the container in plaintext. This means that a malicious actor could extract these values pretty easily from either the host or the running container depending on which has been compromised. A better approach would be to use AWS Secrets Manager or AWS Parameter Store to store the configuration settings and pull these directly from with your application code. Both AWS services can then be limited to a few select users to manage the configuration, such as engineering leads. With this approach, the configuration is no longer accessible without doing a direct memory dump from within the container.&lt;/p>
&lt;p>When we come around to highly confidential information, we should be looking into the use of Nitro Enclaves. AWS Nitro Enclaves enables customers to create isolated compute environments to further protect and securely process highly sensitive data such as personally identifiable information (PII), healthcare, financial, and intellectual property data within their Amazon EC2 instances.&lt;/p>
&lt;h2 id="enforcing-compliance-in-zero-trust-architectures">Enforcing Compliance In Zero Trust Architectures&lt;/h2>
&lt;p>Having a set of guiding principals is a good start towards a zero-trust architecture but the most important aspect of it is observation and compliance.&lt;/p>
&lt;h3 id="observability">Observability&lt;/h3>
&lt;p>One of the most important aspects of zero-trust architectures is the use of monitoring. AWS, as mentioned above, has a number of great tools built into the products for the purposes of monitoring and alerting. Monitoring ideally is continuous, but it can also be periodic in nature. Alerting should be setup for the aspects of the systems that you are most concerned about. For example, you may have an alert for when a critical security group is modified. The remediation of the alert may be automatic, but you should be aware that the violation has occurred in the first place.&lt;/p>
&lt;h3 id="compliance">Compliance&lt;/h3>
&lt;p>There are two forms of compliance that we need to consider: pre-deployment / post-deployment.&lt;/p>
&lt;p>Pre-deployment validation can be a little tricky depending on the toolchain that you use. If you use &lt;a href="https://www.terraform.io/">Terraform&lt;/a> then you have a couple of choices: &lt;a href="https://www.hashicorp.com/products/terraform/editions/cloud">Terraform Enterprise&lt;/a> and &lt;a href="https://spacelift.io/">SpaceLift&lt;/a>. Both allow for a form of codified policies which can prevent resources being created if they don&amp;rsquo;t match specific standards.&lt;/p>
&lt;p>Post-deployment could easily be handled by tools like &lt;a href="https://cloudcustodian.io/">CloudCustodian&lt;/a>. CloudCustodian allows you to define a series of policies that ensure your infrastructure follows a set of defined guidelines. Should a policy be violated, you have the choice on whether to act on the violation. For example, you may want to turn off an EC2 instance if the root storage device is not encrypted with a KMS key.&lt;/p>
&lt;p>In reality, you will likely need a combination of pre &amp;amp; post-deployment compliance as there will always be scenarios where infrastructure is changed manually or a malicious actor could spin up new infrastructure.&lt;/p>
&lt;p>Hopefully you now have a good understanding of what is meant by zero-trust architectures and you can leverage some of the tools and techniques mentioned to improve your security posture. I thoroughly recommend that you read through the &lt;a href="https://github.com/ukncsc/zero-trust-architecture">National Cyber Security Centre - Zero Trust Architecture&lt;/a> repository for more information on some of the topics listed in this post.&lt;/p></description></item></channel></rss>