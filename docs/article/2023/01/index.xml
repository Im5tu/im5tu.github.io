<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>January on CodeWithStu's Blog</title><link>https://im5tu.io/article/2023/01/</link><description>Recent content in January on CodeWithStu's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><atom:link href="https://im5tu.io/article/2023/01/index.xml" rel="self" type="application/rss+xml"/><item><title>Observed No. 5 - MACH Architectures</title><link>https://im5tu.io/article/2023/01/observed-no.-5-mach-architectures/</link><pubDate>Mon, 30 Jan 2023 02:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-5-mach-architectures/</guid><description>&lt;p>Welcome to the fifth edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at MACH architectures.&lt;/p>
&lt;h2 id="what-are-mach-architectures">What are MACH architectures?&lt;/h2>
&lt;p>A MACH architecture is a set of principles for modern application architectures. MACH is a relatively new term in the industry and is quickly gaining popularity because of the level of interoperability, scalability and composability. Many systems today are being built like lego pieces on cloud infrastructure which may be composed to create larger systems with well-defined boundaries thanks to movements like Domain Driven Design.&lt;/p>
&lt;p>The MACH acronym consists of four distinct parts:&lt;/p>
&lt;ul>
&lt;li>M is for Microservices: Individual pieces of business functionality that are independently developed, deployed and managed.&lt;/li>
&lt;li>A is for API-first: All functionality is available on the API.&lt;/li>
&lt;li>C is for Cloud-Native SaaS: SaaS that leverages the cloud beyond storage and hosting, including elastic scaling and automatic updating.&lt;/li>
&lt;li>H is for Headless: Front-end presentation is decoupled from back-end logic and channel, programming language, and is framework agnostic.&lt;/li>
&lt;/ul>
&lt;p>The above definitions come directly from the MACH alliance.&lt;/p>
&lt;h3 id="what-is-the-mach-alliance">What is the MACH Alliance?&lt;/h3>
&lt;p>The MACH Alliance is a not-for-profit industry body that advocates for open and best-of-breed enterprise technology ecosystems. The Alliance is a vendor-neutral institution that provides resources, education and guidance through industry experts to support companies on their journey.&lt;/p>
&lt;h2 id="what-are-the-benefits-of-mach-architectures">What are the benefits of MACH architectures?&lt;/h2>
&lt;p>There are many benefits of MACH architecture, including the following:&lt;/p>
&lt;ol>
&lt;li>Faster development with reduced risk: Quickly bring ideas to market with a quicker route to MVP by utilising independent microservices which don&amp;rsquo;t affect the rest of the architecture negatively.&lt;/li>
&lt;li>Best-of-breed technology: Utilise the best available technology whilst integrating existing functionality where it&amp;rsquo;s appropriate to do so.&lt;/li>
&lt;li>Reducing the need to upgrade: Automatic and non-breaking releases eliminate the worry of disruptive upgrades as they communicate through your APIs, creating an excellent level of separation.&lt;/li>
&lt;li>Easy customisation and innovation: Quickly adapt to changing customer needs with the ability to change and innovate the customer experience constantly.&lt;/li>
&lt;/ol>
&lt;h2 id="what-are-the-drawbacks-of-mach-architectures">What are the drawbacks of MACH Architectures?&lt;/h2>
&lt;p>When evaluating any architectural design, we must consider the impacts of our decision to ensure that it&amp;rsquo;s the right one. MACH-based architectures are no different, and it&amp;rsquo;s not all sunshine and rainbows, especially for smaller businesses:&lt;/p>
&lt;p>Microservice can be costly to develop and maintain, leading to a complex architecture. As more microservices are developed, additional technologies such as API gateways, service discovery, and service meshes are needed to manage them effectively.&lt;/p>
&lt;p>Ensuring consistency and a well-designed API surface takes a lot of skill, experience and maintenance. Any API would also need to consider how to version the API to ensure that clients do not break.&lt;/p>
&lt;p>On-premise deployments are still a problem, typically found in finance and government-related areas.&lt;/p>
&lt;p>Cost. Whenever we talk about utilising the cloud and expanding into many microservices, there is always an inherent cost. Some companies can deal with these costs, but purse strings are generally tightening a lot at the moment.&lt;/p>
&lt;h2 id="is-a-mach-architecture-right-for-you">Is a MACH architecture right for you?&lt;/h2>
&lt;p>Sitecore has compiled 11 great questions to ask before you consider transitioning into the MACH architecture strategy:&lt;/p>
&lt;ol>
&lt;li>Does it feature true microservices?&lt;/li>
&lt;li>Can you execute phased roll-outs?&lt;/li>
&lt;li>Does it support a best-of-breed approach?&lt;/li>
&lt;li>Is it built with APIs from the ground up, or has it adopted an API bolt-on strategy?&lt;/li>
&lt;li>Can you access quality documentation?&lt;/li>
&lt;li>How are integrations completed?&lt;/li>
&lt;li>Does it offer limitless scalability?&lt;/li>
&lt;li>Is the software delivered as-a-service (SaaS)?&lt;/li>
&lt;li>Do updates and upgrades happen via continuous delivery without breaking changes?&lt;/li>
&lt;li>Can you &amp;ldquo;see&amp;rdquo; the administrative or buyer interface without development time?&lt;/li>
&lt;li>Can you develop and deploy the user experience freely and flexibly?&lt;/li>
&lt;/ol>
&lt;p>My view on technology is that there is never a one size fits all approach, and MACH architectures are no different. From what I&amp;rsquo;ve seen, most companies are already ~75% of the way to a MACH architecture. It&amp;rsquo;s hard for anyone to realise the constraints of any given business from the outside, but these are some excellent principles to follow where we can.&lt;/p>
&lt;p>I would love to hear your thoughts on these principals.&lt;/p>
&lt;p>&lt;strong>📣 Get the Weekly Newsletter Straight to Your Inbox! 📣&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 4 - Emerging Pattern: Centralised Ingress</title><link>https://im5tu.io/article/2023/01/observed-no.-4-emerging-pattern-centralised-ingress/</link><pubDate>Mon, 23 Jan 2023 02:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-4-emerging-pattern-centralised-ingress/</guid><description>&lt;p>Welcome to the fourth edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at a common pattern emerging across the industry: Centralised Ingress.&lt;/p>
&lt;h2 id="what-is-ingress-traffic">What is ingress traffic?&lt;/h2>
&lt;p>Ingress traffic refers to communication with your network from outside its perimeter. Typically when referring to ingress traffic, we talk about traffic from external consumers of our services, usually via HTTP or HTTPS. However, ingress could be any external traffic trying to hit our network. For example, it could be a Google search bot or an attacker trying to connect to our Redis cluster(s).&lt;/p>
&lt;h2 id="why-are-companies-centralising-ingress">Why are companies centralising ingress?&lt;/h2>
&lt;p>In the past, the companies implementing centralised ingress have been limited to large companies with tens of thousands of employees. As the technology improves and teams adopt more agile DevOps practices, companies as small as 50 people are implementing this pattern.&lt;/p>
&lt;p>To get a good understanding of why this is an emerging pattern, let’s take a look at some of the benefits that companies will get by implementing a centralised ingestion layer:&lt;/p>
&lt;ol>
&lt;li>Improved security: Directing all incoming traffic to a central point can be more easily monitored for security threats, and any malicious traffic can be blocked before it reaches the internal network. Centralisation also reduces the total attack surface by keeping everything private, that should be private.&lt;/li>
&lt;li>Simplified network architecture: Directing all incoming traffic to a central point can simplify the overall network architecture and make it easier to understand and troubleshoot. The simplification may also lead to cost savings by reducing the total number of load balancers, depending on the final architecture.&lt;/li>
&lt;li>Additional functionality: Using a centralised ingestion point as a reverse proxy can provide other functionality like SSL termination, caching, rate limiting, and a starting point for tracing or authentication.&lt;/li>
&lt;/ol>
&lt;p>From what I’ve seen, companies tend to move towards a centralised point of ingestion primarily for security benefits, closely followed by the additional functionality they receive.&lt;/p>
&lt;p>Companies typically look at two main additional pieces of functionality:&lt;/p>
&lt;ol>
&lt;li>Rate limiting&lt;/li>
&lt;li>Tracing&lt;/li>
&lt;/ol>
&lt;p>Centralising the rate-limiting of all external clients in a centralised manner allows development teams to reduce the total complexity of their applications because they essentially offload the work to the point of ingress. Teams may still choose to have rate limiting for their internal clients, but the centralised view can provide rate limits that are not otherwise possible to implement in each application.&lt;/p>
&lt;p>With Tracing, a centralised ingress is the starting point for all requests regardless of destination. Apart from the standard benefits of having a distributed tracing system, one key benefit of starting the tracing at a single entry point is that you can generate metrics for every endpoint in your system, including any associated monitoring and alerting.&lt;/p>
&lt;h2 id="why-wouldnt-you-centralise-your-ingress">Why wouldn’t you centralise your ingress?&lt;/h2>
&lt;p>Whilst there are a lot of positives of centralising your ingress traffic, there may be occasions where you shouldn’t. These include:&lt;/p>
&lt;ol>
&lt;li>Scaling: Centralising your ingress traffic can create a bottleneck if the point of ingestion cannot handle a large amount of incoming traffic. This can lead to increased latency and decreased performance, or in some cases, a complete denial of service.&lt;/li>
&lt;li>Complexity: Centralising your ingress traffic can add complexity to the architecture, making it more difficult to understand and troubleshoot. Moreover, it can increase the risk of any deployments done to the ingestion layer, which must be managed accordingly.&lt;/li>
&lt;li>Limited flexibility: Centralising your ingress traffic can limit how traffic is directed and managed. It may be harder to implement more advanced routing rules or to route traffic to different services based on certain conditions.&lt;/li>
&lt;/ol>
&lt;p>As with any technology, the benefits and drawbacks need to be reviewed by your organisation against any requirements that they have. When deploying a centralised ingress layer, you also need to consider how many you will need to deploy because, ideally, you would have at least two different ingestion layers—one for production and one for testing.&lt;/p>
&lt;p>If you want to see a video on deploying a centralised ingress network on AWS, please drop me a message or a comment.&lt;/p>
&lt;p>&lt;strong>📣 Get the Weekly Newsletter Straight to Your Inbox! 📣&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 3 - Understanding Split Horizon DNS: How it works and How to Implement it in AWS</title><link>https://im5tu.io/article/2023/01/observed-no.-3-understanding-split-horizon-dns-how-it-works-and-how-to-implement-it-in-aws/</link><pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-3-understanding-split-horizon-dns-how-it-works-and-how-to-implement-it-in-aws/</guid><description>&lt;p>Welcome to the third edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at Split Horizon DNS.&lt;/p>
&lt;h2 id="what-is-split-horizon-dns">What is Split Horizon DNS?&lt;/h2>
&lt;p>Split Horizon DNS is a technique used in DNS to provide different responses to queries depending on where the query originates. For example, a DNS request originating from inside your network may elicit a different response to a DNS request from a consumer of your application.&lt;/p>
&lt;p>Splitting the responses by source can help ensure that only the resources which should be exposed to the internet are exposed. For example, an internal-only admin service would be an ideal candidate for not exposing to the internet, but we would want it addressable by our internal networks. In this case&lt;/p>
&lt;p>With Split Horizon DNS, each zone responds with an authoritative answer. For example, in a traditional DNS setup where the DNS is not split, there is only one authoritative answer - your primary DNS nameserver. With split DNS, your internal DNS will respond with one answer, and the external DNS will respond with another - typically for an internal and external load balancer, respectively.&lt;/p>
&lt;p>Split Horizon DNS is also known as Split View DNS, Split DNS or Split Brain DNS.&lt;/p>
&lt;h2 id="how-to-set-up-split-horizon-dns-in-aws">How to set up Split Horizon DNS in AWS?&lt;/h2>
&lt;p>To configure Split Horizon DNS, you perform the following steps:&lt;/p>
&lt;ol>
&lt;li>Create public and private hosted zones with the same name, for example: mydomain.com&lt;/li>
&lt;li>Associate one or more VPCs with the private hosted zone. Route 53 Resolver uses the private hosted zone to route DNS queries in the specified VPCs.&lt;/li>
&lt;li>Create records in each hosted zone. Records in the public-hosted zone control where internet traffic is routed, whilst records in the private-hosted zone control how traffic is routed internally.&lt;/li>
&lt;li>Query your DNS&lt;/li>
&lt;/ol>
&lt;p>If you have any questions or comments, please don’t hesitate to contact me either in the comments, on Twitter or any medium listed on my website! I’d love to hear your thoughts. Subscribe to the newsletter below!&lt;/p>
&lt;p>&lt;strong>📣 Get the Weekly Newsletter Straight to Your Inbox! 📣&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 2 - Upgrade Your Terraform Modules</title><link>https://im5tu.io/article/2023/01/observed-no.-2-upgrade-your-terraform-modules/</link><pubDate>Mon, 09 Jan 2023 00:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-2-upgrade-your-terraform-modules/</guid><description>&lt;p>Welcome to the second edition of Observed! Your weekly newsletter, where I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at a technique you can use to upgrade your Terraform modules.&lt;/p>
&lt;p>In case you aren’t sure what a Terraform module is, they are a self-contained package of Terraform configurations managed as a group. Modules can be used to create reusable components, improve organization and structure, and improve the reusability and maintainability of your infrastructure.&lt;/p>
&lt;p>Over the course of the last 4/5 years, I’ve noticed that there is always a trend within companies to build modules for specific things/use cases. Rarely do I see these teams account for the one thing they need to operate the infrastructure they make. That is monitoring/alerting.&lt;/p>
&lt;p>Typically, a team would use an existing module or create their own and then create a load of resources for their monitoring/alerting needs. They would re-write this same terraform code over and over.&lt;/p>
&lt;p>There are two different approaches that I take with my teams when adding monitoring/alerting:&lt;/p>
&lt;p>Create a separate module which contains all of the monitoring/alerting&lt;/p>
&lt;p>Embed the monitoring/alerting resources into the same module that you develop&lt;/p>
&lt;p>The approach we take largely depends on the resources that we are creating the monitoring for. Where possible, we try not to reinvent the wheel because, as you may have experienced, Terraform can be a little bit tricky to get right sometimes.&lt;/p>
&lt;p>I like to have this reusable component in place because I want the teams I work with to fall into the pit of success. That is, their experience will be better if they reuse the existing work and contribute to it where it makes sense. That said, I don’t believe there is a one-size-fits-all when it comes to any technology, so let’s quickly run down the benefits of each approach.&lt;/p>
&lt;h3 id="approach-1---separate-module">Approach 1 - Separate module&lt;/h3>
&lt;p>Using a separate module allows for the most flexibility but also takes much of the duplication out of our code. This means that the same alerts, such as CPU %, can be reused in various scenarios.&lt;/p>
&lt;p>However, this approach, whilst helpful, isn’t as optimal as I would personally like because it relies on two key things: discoverability and remembering to implement. Your company may have an excellent solution for discovering Terraform modules, but I’m yet to see a great implementation. I’d be very interested in speaking with you if you have a good implementation!&lt;/p>
&lt;h3 id="approach-2---embedded-within-the-module">Approach 2 - Embedded within the module&lt;/h3>
&lt;p>The second approach gives us the pit of success we are after because developers do not have to consider monitoring as the module embeds this with sensible defaults.&lt;/p>
&lt;p>I generally find the most optimal solution to combine the approaches mentioned above. We typically build the monitoring/alerting into a separate module and then embed that into the module that creates the resources we are interested in. This gives us the best of both worlds!&lt;/p>
&lt;h3 id="what-should-an-alert-look-like">What should an alert look like?&lt;/h3>
&lt;p>Getting alerts right can be a little tricky, but there are some key steps that you can take to make sure your alerts can be actioned appropriately:&lt;/p>
&lt;ol>
&lt;li>Actionable: It should clearly indicate what action should be taken in response to the alert.&lt;/li>
&lt;li>Timely: It should be triggered as close to the event as possible so that the appropriate action can be taken in a timely manner.&lt;/li>
&lt;li>Accurate: It should only be triggered when there is a real issue and not due to false positives.&lt;/li>
&lt;li>Specific: It should provide enough information to allow someone to understand and address the issue without requiring further investigation.&lt;/li>
&lt;li>Relevant: It should only be sent to people responsible for or able to take action on the issue.&lt;/li>
&lt;/ol>
&lt;p>With my teams, I always try to look at it from the perspective of “how would I want to deal with this at 2 am after a long week”. With this perspective, I find that my teams and I create a high standard of alerts. Couple this with the terraform module approach above, and you should take your Terraform to the next level!&lt;/p>
&lt;p>Before I leave you to get on with your week, I want to let you know about something happening pretty soon. I’m launching a &lt;a href="https://youtube.com/@DevOpsWithStu?sub_confirmation=1">DevOps-focused YouTube channel&lt;/a>! On the 20th Jan 2023, DevOpsWithStu will go live with three videos. This channel will be the same as this newsletter, with helpful tutorials on AWS, Terraform and general DevOps topics. If you like the content in this newsletter, I’m sure you’ll enjoy the content going out on YouTube, so hit that subscribe button &amp;amp; notification bell to get alerts for when new content is available!&lt;/p>
&lt;p>Side note: I also own the &lt;a href="https://youtube.com/@CodeWithStu?sub_confirmation=1">CodeWithStu YouTube channel&lt;/a>, which is focused on the .NET stack.&lt;/p>
&lt;p>&lt;strong>📣 Get the Weekly Newsletter Straight to Your Inbox! 📣&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item><item><title>Observed No. 1 - VPC Endpoint Policies</title><link>https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/</link><pubDate>Mon, 02 Jan 2023 01:00:00 +0000</pubDate><guid>https://im5tu.io/article/2023/01/observed-no.-1-vpc-endpoint-policies/</guid><description>&lt;p>Welcome to the very first edition of Observed! Each week I bring you a tip you can implement in your infrastructure across many categories like AWS, Terraform and General DevOps practices. This week&amp;rsquo;s edition looks at VPC endpoint policies in AWS.&lt;/p>
&lt;h2 id="what-are-vpc-endpoints">What Are VPC Endpoints?&lt;/h2>
&lt;p>VPC endpoints are network interfaces you can create in your VPC to enable communication between your VPC and other AWS services without using an Internet gateway, VPN, or VPC peering. VPC Endpoints allow you to secure and control access to both AWS services and your services by:&lt;/p>
&lt;p>Enabling access to AWS services from within your VPC without requiring a NAT gateway or VPN connection.&lt;/p>
&lt;p>Enabling private connectivity between your VPC and other AWS services, such as Amazon S3, Amazon SQS, and Amazon SNS allows you to keep your data and communication within the AWS network, improving security and reducing data transfer costs.&lt;/p>
&lt;p>Enabling access to AWS services from on-premises networks using AWS Direct Connect allows you to create a secure, private connection between your on-premises network and your VPC and then use VPC endpoints to access AWS services without going over the Internet.&lt;/p>
&lt;p>By default, VPC endpoints allow full access to the resources they are created for, so we need to add policies to guard against unwanted actions. For example, if you create a VPC endpoint for SQS, then the endpoint will allow any SQS traffic over the network. This is where VPC endpoint policies come into play.&lt;/p>
&lt;h2 id="vpc-endpoint-policies">VPC Endpoint Policies&lt;/h2>
&lt;p>One overlooked factor of VPC endpoints is the policies you can attach to them. VPC endpoint policies are an optional series of rules to control access to your VPC endpoint, which are attached to the endpoint itself rather than to an individual resource or service. Some common use cases for VPC endpoint policies include:&lt;/p>
&lt;p>Allowing only specific AWS accounts to access your VPC endpoint ensuring that only authorised users can access it.&lt;/p>
&lt;p>Allowing only specific IAM users or roles to access your VPC endpoint, which is useful for controlling access on a more granular level, allowing you to grant or deny access to individual IAM users or roles.&lt;/p>
&lt;p>Allowing only specific VPCs to access your VPC endpoint. This can be useful for limiting access to your VPC endpoint to only specific VPCs, such as VPCs that belong to your organisation.&lt;/p>
&lt;p>The policies themselves follow the standard IAM policy format, with the slight difference that you should only reference resources for the specific type of VPC endpoint. For example, don&amp;rsquo;t try to apply SNS permissions on an SQS VPC endpoint.&lt;/p>
&lt;p>Let’s take a look at an example VPC endpoint policy:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Statement&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Sid&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;PreventUnintendedResourcesAndPrincipals&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Principal&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;*&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Action&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;s3:*&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Effect&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;Deny&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Resource&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;*&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;Condition&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;StringNotEquals&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;aws:ResourceOrgId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;o-XXXXXXX&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;aws:PrincipalOrgId&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;o-XXXXXXX&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This policy prevents S3 usage outside the current organisation by using global conditional keys. When a principal makes a request to AWS, AWS gathers the request information into a request context. This request context is made available to you via the Condition element of the statement block in the policy document.&lt;/p>
&lt;p>The action section of the policy can either be wildcarded like I have in the example above, or you can limit it to specific actions such as s3:PutObject. When I create my policies, I try to use a combination of Effect:Deny and NotAction. I believe that being more specific about what actions are allowed on a VPC Endpoint leads to a better security posture.&lt;/p>
&lt;p>You can see which AWS services support VPC Endpoint Policies, and other valuable information, by using the describe-vpc-endpoint-services CLI command and checking for the field VpcEndpointPolicySupported in the response.&lt;/p>
&lt;p>I believe VPC Endpoint Policies are critical for securing infrastructure in sensitive environments, which is why they are part of my Well Architected Toolkit, which I’ll release later this year. Have you implemented VPC Endpoint Policies? What use cases have you found for them? Let me know how you use them below or reach out to me on &lt;a href="https://twitter.com/codewithstu">Twitter&lt;/a>.&lt;/p>
&lt;p>&lt;strong>📣 Get the Weekly Newsletter Straight to Your Inbox! 📣&lt;/strong>&lt;/p>
&lt;p>Don&amp;rsquo;t miss out on the latest updates! Subscribe to the &lt;a href="https://news.codewithstu.tv">Observed! Newsletter&lt;/a> now and stay up-to-date with the latest tips and tricks across AWS, Devops and Architecture. &lt;a href="https://news.codewithstu.tv">Click here&lt;/a> to subscribe and start receiving your weekly dose of tech news!&lt;/p></description></item></channel></rss>